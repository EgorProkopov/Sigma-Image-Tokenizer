\documentclass[times,specification,annotation]{itmo-student-thesis}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{makecell}

%% Опции пакета:
%% - specification - если есть, генерируется задание, иначе не генерируется
%% - annotation - если есть, генерируется аннотация, иначе не генерируется
%% - times - делает все шрифтом Times New Roman, собирается с помощью xelatex
%% - languages={...} - устанавливает перечень используемых языков. По умолчанию это {english,russian}.
%%                     Последний из языков определяет текст основного документа.

%% Делает запятую в формулах более интеллектуальной, например:
%% $1,5x$ будет читаться как полтора икса, а не один запятая пять иксов.
%% Однако если написать $1, 5x$, то все будет как прежде.
\usepackage{icomma}

%% Один из пакетов, позволяющий делать таблицы на всю ширину текста.
\usepackage{tabularx}

%% Данные пакеты необязательны к использованию в бакалаврских/магистерских
%% Они нужны для иллюстративных целей
%% Начало
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{filecontents}
%% Конец

%% Указываем файл с библиографией.
\addbibresource{bachelor-thesis.bib}


\begin{document}
\chapter{Исследование алгоритмов токенизации изображений на основе матричных разложений}

\section{Токенизация изображений на основе быстрого преобразования Фурье}

\subsection{Анализ применения быстрого преобразования Фурье для токенизации изображений}

Рассмотрим черно-белое изображение $i(x, y)$ размера $(M, M)$. Двумерное дискретное преобразование Фурье позволяет получить частотное представление изображения $I(u, v)$ как

$$
I(u, v) = \sum_{x=0}^{M-1}\sum_{y=0}^{M-1} i(x, y) e^{-i2\pi\Big(\dfrac{ux}{M} + \dfrac{vx}{M}\Big)}
$$

Поскольку вычислительная сложность алгоритма быстрого преобразования Фурье составляет $O(M^2 \log(M^2))$ вместо $O((M)^4)$, при этом позволяя получить тот же самый результат, далее будет применяться именно этот алгоритм. 

$I(u, v)$ можно представить как изображение с комплекснозначной интенсивностью пикселей, либо же как двухканальное изображение. Для наглядности визуализации используется спект мощности, определяемый как 

$$
I^{power} = \sqrt{(Re(I))^2 + (Im(I))^2}
$$

Также, поскольку зачастую в спектрах мощностей присутствуют значительные пики (большие значения) малого количества частот, используется масштабирование спектра мощности

$$
\log(I^{power}) \quad \text{или} \quad \sqrt{I^{power}}
$$

В дальнейшем, при вычислении спектра мощности будет использоваться именно метод масштабирования на основе логарифма.

Также стоит отметить, что при визуализации или построении низкочастотного фильтра, используется центрированный спектр мощности. Поскольку в $I^{power}$ низким частотам соответствуют значения на краях, для удобства последующей обработки применяется центральная симметрия.

\subsection{Построение низкочастотного фильтра}

Поскольку высокие частоты содержат лишь малую долю информации, можно построить фильтр низких частот, отсекающий высокие частоты. Такой подход позволяет значительно сократить количество обрабатываемых данных при сохранении основной информации, а также позволяет очистить исходное изображение от шумов. Обычно, для построения такого фильтра используется отбор частот с помощью евклидовой расстояния до центра спектра мощности.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/solutions_analysis/fourier/low_pass_filter.png}
    \label{fig:svd_approx_im_fix_rank}
    \caption{Фильтр низких частот с использованием евклидова расстояния до центра спектра мощности.}
\end{figure}

В дальнейшем выход низкочастотного фильтра будет обрабатываться нейронной сетью. Так как нейронные сети обрабатывают матрицы, использование данного фильтра приведет к тому, что в углах выхода низкочастотного фильтра будут находиться нули. В свою очередь, это приведет к лишним вычислениям и затратам памяти, не улучшающих итоговый результат работы модели. Поэтому, для того, чтобы сохранить больше полезной информации, выполним отбор частот не с помощью евклидова расстояния, а с помощью расстояния Чебышева.

% нужна картинка низкочастотного фильтра с расстоянием Чебышева

Для обработки многоканальных (в том числе и цветных) изображений, представим их с помощью трёх матриц, к каждой из которых применим быстрое преобразование Фурье и низкочастотный фильтр по одинаковой маске. В результате получим тензор размерности (6, $s$, $s$), где $s$ - размер фильтра, то есть предельное расстояние (с использованием нормы Чебышева), при котором частоты сохраняются

\subsection{Вычисление размера фильтра}
Размер фильтра может быть задан как фиксированный гиперпараметр. Такой фильтр назовем статическим фильтром.

Однако, в этом случае результат работы модели будет сильно отличаться в зависимости от размера входного изображения. Так, при обработке больших изображений, многократно больших, чем размер фильтра, будут отбираться только самые низкие частоты. В это же время, при обработке изображений, размер которых соответствует размеру фильтра, будут учитываться абсолютно все частоты. Это делает вычисление размера фильтра важной задачей при построении токенизатора на основе быстрого преобразования Фурье.

Очевидно, что размер фильтра должен коррелировать с размером обрабатываемого изображения. Это делает размер фильтра $s$ динамически изменяемым параметром. Для определения $s$ воспользуемся центрированным отмасштабированным спектром мощности. Можно заметить, что низкие частоты имеют значительно большую интенсивность, чем высокие частоты. Сумму всех интенсивностей назовем энергией спектра мощности 

$$
E = \sum\limits_{i=-M/2}^{M/2}\sum\limits_{j=-M/2}^{M/2} I^{power}(i, j)
$$ 

Поскольку для построения токенизатора нам необходимы в первую очередь низкие частоты, будем увеличивать размер фильтра $s$ таким образом, пока доля охватываемой фильтром энергии спектра мощности не превысит $pE$, где $p \in (0, 1]$ - гиперпараметр, который назовем долей энергии спектра мощности.

Таким образом, значение $s$ можно вычислить как

$$
\sum_{i=-s/2}^{s/2}\sum_{j=-s/2}^{s/2} I^{power}(i, j) \leq pE < \sum_{i=-\frac{s+1}{2}}^{\frac{s+1}{2}}\sum_{j=-\frac{s+1}{2}}^{\frac{s+1}{2}} I^{power}(i, j)
$$

Для вычисления значения $s$ в программе используются двумерные кумулятивные суммы.

Такой фильтр, размер которого вычисляется с помощью относительной энергии спектра мощности, назовем динамическим фильтром. 

Статический и динамический фильтры обладают следующими преимуществами и недостатками:

\begin{itemize}
    \item Размер статического фильтра всегда одинаков, соответственно, после токенизации, количество токенов входной последовательности трансформера будет неизменным. Это делает количество требуемых вычислительных ресурсов независимым от размера изображения. В свою очередь размер динамического фильтра зависит от размера входного изображения, что может привести к слишком большой длине входной последовательности при обработке изображений большого размера
    \item В отличие от статического фильтра, динамический фильтр позволяет более гибко отбирать частоты, поскольку размер фильтра зависит от того, что изображено на изображении. Так, если изображение состоит из слабоменяющихся, больших и однотонных элементов, то у такого изображения будут преобладать низкие частоты, а соответственно, размер фильтра будет меньше. Если на изображении преобладают высокие частоты, то размер фильтра будет больше.
\end{itemize}



\subsection{Построение токенизатора на основе низкочастотного фильтра}

Для построения токенизатора изображения на основе быстрого преобразования Фурье построим низкочастотный фильтр. Маску низкочастотного фильтра будем формировать на основе нормы Чебышева, поскольку в этом случае маска получается квадратная. В результате, цветное изображение размерности $(3, M, M)$ преобразуется в тензор размерности $(6, s, s)$. 

Были рассмотрены различные способы преобразования этого тензора в последовательность векторов.

\subsubsection{Разбиение на патчи}

Данный способ повторяет метод, предложенный в Vision Transformer, однако разбиение на патчи применяется не напрямую к изображению, а к выходу низкочастотного фильтра.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]
    {images/research/fourier/patches_split.png}
    \caption{Пример разбиения выхода низкочастотного фильтра на 4 патча.}
\end{figure}

После разбиения на патчи, каждый патч выпрямляется в вектор. Таким образом, тензор размерности 

$$ (6, s, s)$$ 

преобразуется в последовательность векторов размерности 

$$\Big(\dfrac{s^2}{s_p^2}, 6 \cdot s_p^2\Big)$$ 

где $s_p$ - размер одного патча. После этого преобразования каждый вектор полученной последовательности проецируется с помощью линейного полносвязного слоя, называемого слоем проекции, в пространство токенов трансформера. Эта проекция необходима, так как размерность векторов полученной последовательности может не совпадать с требуемой размерностью токенов для обработки их трансформером. 

В программе процесс разбиения изображения на патчи, их выравнивание и линейную проекцию линейным полносвязным слоем можно заменить на свёрточный слой нейронной сети с ядром свертки и шагом свертки равными размеру патча.

К полученной последовательности токенов добавляется токен класса и позиционное кодирование, аналогичное позиционному кодированию в Vision Transformer.

\subsubsection{Разбиение на интервалы}

Поскольку выход низкочастотного фильтра отображает не пространственные взаимосвязи пикселей на изображении, а влияние тех или иных частот, рассмотрен вариант разбиения выхода низкочастотного фильтра на интервалы. Такой подход позволяет сгруппировать близкие друг с другом частоты в один вектор.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]
    {images/research/fourier/bins_split.png}
    \caption{Пример разбиения выхода низкочастотного фильтра на 4 интервала.}
\end{figure}

В этом случае выход низкочастотного фильтра разбивается на $n_b$ ``полос`` - интервалов. Количество интервалов $n_b$ - гиперпараметр. Каждый такой интервал выпрямляется в вектор. Таким образом, исходный тензор размерности 

$$
(6, s, s) 
$$

преобразуется в последовательность векторов размерности

$$
\Big(n_b, \dfrac{s^2}{n_b}\Big)
$$

Каждый вектор полученной последовательности проецируется с помощью линейного полносвязного слоя в в пространство токенов трансформера. Аналогично методу с разбиением на патчи, эта проекция необходима для приведения полученных векторов к размерности, которую возможность обработать трансформером.

Данный способ токенизации возможен только при использовании статического фильтра низких частот, так как в случае использования динамического фильтра, размер фильтра $s$ - также динамический. Это значит, что последовательность векторов, полученная после разбиения на интервалы выхода низкочастотного фильтра, состоит из векторов динамической размерности $\dfrac{s^2}{n_b}$. Это делает невозможным их проекцию в пространство фиксированной размерности с помощью линейного полносвязного слоя.

К полученной последовательности токенов добавляется токен класса и позиционное кодирование, аналогичное позиционному кодированию в оригинальной модели Transformer. 

\subsubsection{Пиксельная расстановка}
Поскольку метод разбиения на патчи не обладает недостатками, рассмотренными в методе разбиения на интревалы, рассмотрим способы его углубления. Как ранее было отмечено, процесс разбиения изображения на патчи, а при построении токенизатора на основе быстрого преобразования Фурье - выхода низкочастотного фильтра, можно заменить на сверточный слой с размером свертки и шагом свертки, равным размеру патча.

Важно отметить, что один сверточный слой с ядром свертки размером 5, шагом 1, отступом 1 и без использования нейрона смещения может быть заменен двумя сверточными слоями с ядром свертки размером 3, шагом 1, отступом 1 и также без использования нейрона смещения. В этом случае область, которую обрабатывают эти слои за один шаг остается той же, при этом между двумя сверточными слоями можно добавить больше функций активации, что позволит итоговой нейронной сети аппроксимировать гораздо более сложные функции. При этом уменьшится количество параметров: при использовании сверточного слоя с ядром свертки размером 5, количество параметров на одно ядро становится равным 25, а при использовании двух слоев с ядром свертки размером 3, эквивалентное количество параметров равно 18. 

Данный процесс ``разложения`` свёрточных слоёв на свёрточные слои с ядрами свёртки размером 3 можно применить и для свёрточных слоёв с размерами ядер свёртки 15 и 17 (что близко к размеру ядра свёртки 16 - наиболее часто используемому размеру патча). Например, сверточный слой с размером ядра свёртки 15 можно разложить на последовательность из 7 свёрточных слоёв с размером ядра свёртки 3, а свёрточный слой с размером ядра свёртки 17 можно разложить на 8 свёрточных слоев с размером ядра свёртки 3. 

Однако, в этом случае не получится изменить размер шага свёртки. Из-за этого, после применения такой последовательности свёрточных слоёв с размером ядра свёртки 3, не изменится размер карт признаков. Однако при этом, количество карт признаков увеличится.

Таким образом, исходный тензор размерности

$$(6, s, s)$$

будет преобразован в тензор размерности 

$$
(s_E, s, s),
$$

где $s_E$ - размерность токенов трансформера. Очевидно, что количество обрабатываемых данных вырастет многократно, при этом количество полезной информации нисколько не изменится. 

Для уменьшения размерности карт признаков при обработке изображений свёрточными нейронными сетями часто используют слои объединения (пулинга). Эти слои позволяют уменьшить размерность карт признаков, пожертвовав частью информации. Этот подход не удовлетворителен, так как потеря информации приведет к ухудшению качества работы итоговой модели. 

Вместо этого, рассмотрим нейронную сеть Super Resolution Generative Adversarial Network (SRGAN). Это генеративная соревновательная нейронная сеть, созданная специально для решения задачи повышения разрешения изображения. В этой модели, для получения карт признаков большей размерности, используется алгоритм пиксельного перемешивания (pixel shuffle). Данный алгоритм группирует карты признаков по 4, после чего объединяет их в одну карту признаков с размером в 2 раза больше по длине и по ширине. В ходе объединения, элементы с одних и тех же позиций разных карт признаков объединяются в квадраты размером 2 на 2 с сохранением исходных позиций. Данный алгоритм позволяет изменить форму обрабатываемых данных, никак не меняя сами данные.

Поскольку текущая задача противоположная, применим алгоритм пиксельной расстановки (pixel unshuffle) - операцию, обратную алгоритму пиксельного перемешивания. В этом случае одну карту признаков будем разбивать на 4 карты с уменьшением исходной длины и ширины в 2 раза. 

В итоге, для того, чтобы заменить свёрточный слой с ядром свёртки размером 16 и шагом 4, применим после каждого свёрточного слоя c ядром свёртки размером 3 и функции активации алгоритм пиксельной расстановки. Количество таких блоков определяется размером заменяемого патча. В случае с размером патча 16, количество таких блоков равно 4, так как $2^4 = 16$. Поскольку в этом случае от размера выхода низкочастотного фильтра требуется кратность 16, рассчитанный размер фильтра округляется в большую сторону до первого значения, кратного 16.


Таким образом, исходный тензор размерности

$$
(6, s, s)
$$

преобразуется в тензор размерности

$$
\Big(s_E, \dfrac{s}{16}, \dfrac{s}{16}\Big)
$$

К получившимуся тензору применяется слой проекции - свёрточный слой с ядром свертки размером 1, шагом 1, размером отступа 0 и без нейрона смещения. Данный тензор выпрямляется по двум последним осям и транспонируется, после чего получается последовательность векторов --- токенов, готовых к обработке моделью трансформер. Такая последовательность имеет форму

$$
\Big(\dfrac{s^2}{16^2}, s_E\Big)
$$

\subsection{Результаты обучения}

 Для проверки гипотезы о работоспособности построенных токенизаторов решалась задача многоклассовой классификации изображений. Набор данных, используемый для обучения - Intel Image Classification Dataset, представленных 17 тысячами изображений 6 классов: ``buildings`` (``здания``), ``forest`` (``лес``), ``glacier`` (``ледник``), ``mountain`` (``гора``), ``sea`` (``море``), ``street`` (``улица``). Набор данных состоит из семантически разнообразных и сбалансированных классов. Исходная выборка разбита на тренировочную выборку, состоящую из приблизительно 14 тысяч изображений, и на валидационную, состоящую из 3 тысяч изображений.

 Обучаемая модель построена из следующих модулей (в порядке обработки входных данных):

\begin{itemize}
    \item Токенизатор на основе быстрого преобразования Фурье
    \item Нейронная сеть Transformer
    \item Классификационная голова на основе многослойного перцептрона
\end{itemize}

Многослойный перцептрон состоит из следующих слоев:

\begin{itemize}
    \item Линейный полносвязный слой с количеством входов, равным размерности токенов трансформера, и 128 выходами
    \item Функция активации ReLU
    \item Линейный полносвязный слой с количеством входов 128 и количеством выходов 6
\end{itemize}

Для обучения использовалась функция потерь перекрестной энтропии.

Были выбраны следующие гиперпараметры:

\begin{itemize}
    \item Размер изображения: 256
    \item Размер патча: 16
    \item Размерность токена: 768
    \item Количество слоев трансформера: 12
    \item Количество голов внимания трансформера: 12
    \item Скрытая размерность многослойного перцетрона внутри трансформера: 3072
    \item Размер низкочастотного фильтра: 256
    \item Размер тренировочного батча: 12
    \item Скорость обучения: 0.0001
    \item Количество эпох: 20
\end{itemize}

Для всех дальнейших экспериментов данная структура сохраняется, за исключением изменения рассматриваемого токенизатора и соответствующих ему гиперпараметров.

\subsubsection{Сравнение методов токенизации с использование быстрого преобразования Фурье}

Результаты обучения представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с различными токенизаторами на основе быстрого преобразования Фурье с моделью Vision Transformer}
  \label{tab:fft-tokenization}
  \begin{tabular}{|l|c|c|}
    \hline
    Метод токенизации & Точность & F1-метрика \\ \hline
    Vision Transformer & 0.79 & 0.79  \\
    FFT-токенизация (патчи) & 0.16 & 0.16  \\ 
    FFT-токенизация (интервалы)  & 0.17 & 0.17  \\ 
    FFT-токенизация (пиксельное перемешивание) & 0.79 & 0.79 \\
    \hline
  \end{tabular}
\end{table}

Из результатов обучения видно, что из всех рассмотренных методов токенизации, единственным работоспособным оказался только метод токенизации с использованием пиксельного перемешивания. Поэтому следующие эксперименты были проведены только с использованием этого метода.

\subsubsection{Сравнение методов токенизации с использованием низкочастотного и высокочастотного фильтров}

Был исследован метод токенизации, аналогичный рассмотренному выше, только с использованием высокочастотного фильтра вместо низкочастотного. Для построения высокочастотного фильтра не применялась центральная симметрия результата работы алгоритма быстрого преобразования Фурье. Было проведено сравнение при различных значениях размера статического фильтра. Результаты обучения и замера метрик представлены в таблице: 

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с токенизатором с высокочастотным фильтром при разных размерах фильтра с токенизатором с низкочастотным фильтром}
  \label{tab:fft-tokenization-unshifted}
  \begin{tabular}{|l|c|c|c|}
    \hline
    Метод токенизации & Размер фильтра & Точность & F1-метрика \\ \hline
    Низкочастотный фильтр & 256 & 0.79 & 0.79 \\
    Высокочастотный фильтр & 64 & 0.32 & 0.25 \\
    Высокочастотный фильтр & 128 & 0.51 & 0.51 \\
    Высокочастотный фильтр & 256 & 0.79 & 0.79 \\
    \hline
  \end{tabular}
\end{table}

Видно, что низкие частоты оказывают значительное влияние на итоговое качество работы модели, что подтверждает изначальную гипотезу о их важности. Также можно заметить, что модель с токенизатором с высокочастотным фильтром и малым размером фильтра, несмотря на серьезное падение значений метрик, работоспособна.

\subsubsection{Сравнение размеров статического низкочастотного фильтра}

Было исследовано влияние размера статического фильтра на обучение модели. Результаты обучения и замера метрик представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с токенизатором с низкочастотным фильтром при разных размерах статического фильтра}
  \label{tab:fft-tokenization-static}
  \begin{tabular}{|l|c|c|c|}
    \hline
    Метод токенизации & Размер фильтра & Точность & F1-метрика \\ \hline
    Vision Transformer & - & 0.79 & 0.79 \\
    Низкочастотный фильтр & 64 & 0.76 & 0.76 \\
    Низкочастотный фильтр & 128 & 0.78 & 0.78 \\
    Низкочастотный фильтр & 256 & 0.79 & 0.79 \\
    \hline
  \end{tabular}
\end{table}

Видно, что серьезное уменьшение размера фильтра (в 4 раза) привело к лишь незначительному снижению качества работы модели как по сравнению с моделью с размером фильтра, равным размеру изображения, так и по сравнению с Vision Transformer. Важно заметить, что уменьшение размера фильтра в 4 раза привело к уменьшению размера входной последовательности токенов для обработки трансформером в 16 раз. 

\subsubsection{Сравнение размеров размеров динамического фильтра}

Было проведено исследование влияния сохраняемой доли энергии спетра мощности на обучение модели. Результаты обучения и замера метрик представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с токенизатором с низкочастотным фильтром при разных размерах динамического фильтра (значение сохраняемой доли энергии указано в скобках возле названия метода токенизации)}
  \label{tab:fft-tokenization-dynamic}
  \begin{tabular}{|l|c|c|c|}
    \hline
    Метод токенизации & Размер фильтра & Точность & F1-метрика \\ \hline
    Vision Transformer & - & 0.79 & 0.79 \\
    Низкочастотный фильтр (0.900) & 96 & 0.74 & 0.74 \\
    Низкочастотный фильтр (0.950) & 128 & 0.76 & 0.76 \\
    Низкочастотный фильтр (0.990) & 208 & 0.77 & 0.76 \\
    \hline
  \end{tabular}
\end{table}

Видно, что заметно не сильное падение значений метрик при значительном уменьшении размера фильтра. Также, если сравнивать результаты обучения с использованием динамического фильтра и с использованием статического фильтра, можно заметить, что при одинаковых размерах фильтра, при использовании динамического фильтра значения метрик оказываются немногим ниже, чем при использовании статического фильтра. Вероятно, на это повлияла динамическая длина последовательности при обучении модели.


\section{Токенизация изображений на основе сингулярного разложения}

\subsection{Анализ применения сингулярного разложения для токенизации изображений}

Сингулярное разложение матрицы $I$ размерности $(M, N)$ --- разложение вида 

$$
I = U\Sigma V^*,
$$

где $\Sigma$ --- диагональная матрица сингулярных чисел размерности $(M, N)$, $U$ --- матрица размерности $(M, M)$, $V$ - матрица размерности $(N, N)$. Матрицы $U$ и $V$ - матрицы левых и правых сингулярных векторов соответственно. Сингулярные числа неотрицательны. Поскольку рассматривается применение сингулярного разложения только для токенизации изображений, то есть вещественных матриц, то $V^* = V^T$.

Компонентой сингулярного выражения назовем сингулярное число и соответствующие ему левый и правый сингулярные вектора.

По свойствам сингулярного произведения, можно одновременно переставлять соответствующие столбцы матриц $U$ и $V$ вместе с диагональными элементами, не меняя результата произведения. Для дальнейшего удобства, переставим компоненты сингулярного разложения в порядке убывания сингулярных чисел.

\subsubsection{Приближение изображения с помощью сингулярного разложения при фиксированном ранге}

По теореме Эккарта-Янга\cite{eckart_young}, если требуется приблизить матрицу $I$ другой матрицей $I_k$ с заранее заданным рангом $k$ (рангом приближения), чтобы значение $||I - I_k||_2^2$ было минимальным, то наилучшая такая матрица получается из сингулярного разложения матрицы $I$ по формуле:

$$
I_k = U_k\Sigma_kV_k^T
$$

где $\Sigma_k$ - матрица $k$ первых (наибольших) сингулярных чисел, а матрицы $U$ и $V$ состоят из соответствующих им сингулярных векторов. Таким образом можно приблизить матрицу $I$ по заданному рангу. 

Представим цветное трехканальное изображение (для упрощения будем рассматривать только квадратные изображения) как набор трех матриц. Тогда, выполнив приближение каждой из этих матриц по выбранному рангу $k$, можно получить приближение исходного изображения.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/solutions_analysis/svd/svd_approx_im_160rank.png}
    \label{fig:svd_approx_im_fix_rank}
    \caption{Сравнение исходного изображения (размером 256 на 256 пикселей) и приближения сингулярным разложением по рангу 160.}
\end{figure}

Из рисунка видно, что при приближении изображения сингулярным разложением нет потери визуальной информации.

При этом, если выбрать сингулярное разложение как основу для токенизации изображений, а компоненты сингулярного разложения представить в виде этих самых токенов, то такое приближение позволит уменьшить длину входной последовательности с 256 до 160.

\subsubsection{Приближение изображения с помощью сингулярного раз-
ложения при динамическом ранге}

При решении задачи приближения некоторой матрицы матрицей меньшего ранга с помощью сингулярного разложения, сингулярные значения, возведенные в квадрат, можно интерпретировать как дисперсию, которую "вкладывает" в итоговый результат каждая компонента. Причем, чем больше значение сингулярного числа, тем большей части информации оно соответствует. 

Поскольку в общем случае изображения могут сильно отличаться друг от друга, и в одном примере для сохранения большей части информации потребуется только, например, 5 первых компонент, а в другом --- больше 100, то для создания токенизатора на основе сингулярного изображения необходим динамический выбор ранга $k$ приближения изображения.   

Поэтому можно вычислить ранг $k$ так, чтобы

$$
    \sum_{i=1}^{k} \sigma_i^2 <= p\sum_{i=1}^{im\_size} \sigma_i^2 < \sum_{i=1}^{k+1} \sigma_i^2,
$$

где $M$ - размер изображения, а $p$ - доля сохраняемой информации, настраиваемый гиперпараметр.

Однако, настройка гиперпараметра $p$ может быть слишком чувствительной при вычислении ранга $k$ с использованием квадратов сингулярных чисел

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/solutions_analysis/svd/svd_lin_vs_square.png}
    \label{fig:svd_lin_vs_square}
    \caption{Сравнение зависимости доли сохраняемой информации изображения от ранга приближения.}
\end{figure}

Для более удобной настройки гиперпараметра $p$, будем вычислять ранг $k$ следующим образом:

$$
    \sum_{i=1}^{k} \sigma_i <= p\sum_{i=1}^{im\_size} \sigma_i < \sum_{i=1}^{k+1} \sigma_i,
$$

\subsection{Построение токенизатора на основе сингулярного разложения}

Для построения токенизатора изображений на основе сингулярного разложения будем использовать приближение изображения по динамическому рангу с линейной суммой сингулярных чисел.

Перепишем разложение матрицы $I_k$:

$$
I_k = U_k\Sigma_kV_k^T = (U_k\sqrt{\Sigma_k})(\sqrt{\Sigma}V_k^T) = U'V'^T
$$

Таким образом получаем матрицы $U'$ и $V'$. Для разбиения на исходной матрицы на набор векторов, разобьем матрицы $U'$ и $V'$ на наборы векторов $u_1, u_2, u_3, ...$ и $v_1, v_2, v_3, ...$, после чего попарно объединим вектора $u_i$ и $v_i$ в один вектор (выполним операцию конкатенации векторов).

Поскольку рассматривается токенизация трехканальных цветных изображений, то такое разбиение выполняется для каждого канала по отдельности. После чего полученные векторы объединяются в один.

$$
t = concat(u_{i1}, v_{i1}, u_{i2}, v_{i2}, u_{i3}, v_{i3}),
$$

где $concat()$ - операция конкатенации векторов, а $u_{i1}, v_{i1}, u_{i2}, v_{i2}, u_{i3}, v_{i3}$ - вектора, соответсвующие $i$-столбцам матриц $U'$ и $V'$ каждого из трех каналов исходного изображения.

Полученный набор векторов преобразуется с помощью линейного полносвязного слоя, слоя проекции, в размерность пространства токенов трансформера. При таком разбиении, исходный тензор размерности

$$
(3, M, M)
$$

преобразуется в последовательность токенов размерности

$$
(k, s_E)
$$

Стоит учесть, что поскольку ранг вычисляется динамически, то при обработке в программе одного минибатча для каждого изображения может быть вычислен различный ранг. В этом случае, выбирается максимальный ранг для всех изображений.

К полученной последовательности добавляется токен класса и позиционное кодирование, аналогичное используемому в модели Transformer.

\subsection{Результаты обучения}

\subsubsection{Сравнение обучения модели с токенизацей на основе сингулярного разложения с Vision Transformer}

Для обучения был построен токенизатор на основе сингулярного разложения с использованием динамического ранга аппроксимации.

Результаты обучения и представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с токенизатором на основе сингулярного разложения (SVD) с моделью Vision Transformer}
  \label{tab:svd-tokenization}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя длина \\ входной последовательности} \\ 
    \hline
    Vision Transformer & 0.79 & 0.79 & 257 \\
    SVD-токенизация & 0.69 & 0.69 & 15.3 \\ \hline
  \end{tabular}
\end{table}

При обучении модели доля сохраненной информации токенизатором на основе сингулярного разложения была выбрана $p = 0.900$.

Из результатов, представленных в таблице, видно, что метод токенизации на основе сингулярного разложения работоспособен. Причем, несмотря на небольшое падение значений метрик, удалось значительно сократить входную длину последовательности.

\subsubsection{Сравнение обучения при различных значениях доли сохраненной информации}

В таблице приведено сравнение результатов обучения модели с токенизатором на основе сингулярного разложения при различных значениях гиперпараметра доли сохраненной информации.

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с токенизатором на основе сингулярного разложения при разных значениях доли сохраненной информации}
  \label{tab:svd-tokenization-disp}
  \begin{tabular}{|l|c|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации}
      & \makecell{Доля \\ сохраненной \\ информации}
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя длина \\ входной \\ последовательности} \\ 
    \hline
    SVD-токенизация & 0.90 & 0.69 & 0.69 & 15.3 \\
    SVD-токенизация & 0.95 & 0.64 & 0.64 & 89.1 \\
    SVD-токенизация & 0.99 & 0.67 & 0.67 & 159.7 \\ \hline
  \end{tabular}
\end{table}

Получены контринтуитивные результаты, при которых большая доля сохранения информации приводит к падению метрик на этапе валидации. Вероятно, это вызвано тем, что большая динамическая длина последовательности приводит к ухудшению обучения модели.

\subsubsection{Проблемы данной версии токенизатора на основе сингулярного разложения}

Текущая версия токенизатора имеет следующие проблемы:

\begin{enumerate}
    \item \textbf{Падение метрик даже при большой доли сохраненной информации.}
        Несмотря на большую долю сохраненной информации и длину входной последовательности, полученные метрики оказались хуже. Это может свидетельствовать о том, что некоторые из компонент сингулярного разложения оказывают негативное влияние на результат работы нейронной сети.
    \item \textbf{Требование к фиксированному размеру изображений.}
        Поскольку в текущей версии токенизатора размерность изображения напрямую влияет на количество параметров токенизатора (на этапе линейной проекции), то возникает требование к фиксированному размеру изображений.
        
    \item \textbf{Отсутствие оптимизации при вычислениях на видеокарте.}
        Вычисление сингулярного выражения тяжело параллелизовать, из-за чего падает общая скорость обучения и работы модели. 
\end{enumerate}

Поскольку токенизатор на основе сингулярного разложения работоспособен и позволяет значительно сократить длину входной последовательности при обработке изображения, необходимо решить существующие проблемы для его эффективного обучения и использования.

\section{Модифицированный токенизатор на основе сингулярного разложения}

\subsection{Построение модифицированного токенизатора на основе сингулярного разложения без функции оценки}

Для решения проблем токенизатора на основе сингулярного разложения необходимо отказаться от использования сингулярного разложения. Алгоритм разложения был заменен на нейронную сеть, вдохновленную сингулярным разложением.

В алгоритме токенизации на основе сингулярного разложения, описанном в предыдущем разделе, токенизация происходит благодаря разбиению матриц $U'$ и $V'$ на наборы векторов $u$ и $v$. Для того, чтобы получить наборы векторов $u$ и $v$ с помощью нейронных сетей, воспользуемся алгоритмом пиксельной расстановки, аналогичным использованному в методе токенизации на основе быстрого преобразования Фурье. 

Для получения каждого из этих наборов построим нейронную сеть, принимающую на вход тензор размерности 

$$
(3, M, M)
$$

Данная нейронная сеть аналогична нейронной сети, предложенной в методе токенизации с использованием быстрого преобразования Фурье. Она также состоит из четырех блоков, каждый блок состоит из свёрточного слоя с размером ядра свёртки равным 3, размером шага равным 1, размером отступа равным 1 и с использованием нейрона смещения. Следом за свёрточным слоем используется слой нормализации и функция активации, после чего применяется алгоритм пиксельной расстановки. 

Таким образом, исходный тензор преобразуется в тензор размерности

$$
\Big(3 \cdot 4^4, \dfrac{M}{16}, \dfrac{M}{16}\Big)
$$

Данный тензор обрабатывается слоем проекции - свёрточным слоем с ядром свёртки размером 1, шагом свёртки размером 1, отступом размером 0 и без нейрона смещения. После этого, данный тензор выпрямляется по двум последним осям (``по ширине`` и ``по высоте``) и транспонируется. В результате получается тензор, описывающий последовательность векторов и имеющий размерность

$$
\Big(\dfrac{M^2}{16^2}, s_E\Big)
$$

Таким образом получаются наборы векторов $u$ и $v$. Аналогично методу токенизации на основе сингулярного разложения, два этих набора векторов объединяются в результате конкатенации соответствующих токенов. 

В результате получается тензор размерности

$$
\Big(\dfrac{M^2}{16^2}, 2 \cdot s_E\Big)
$$

Данный тензор с помощью линейного полносвязного слоя проецируется в пространство токенов трансформера. Итоговый тензор, описывающий последовательность токенов на вход трансформера, имеет размерность

$$
\Big(\dfrac{M^2}{16^2}, s_E\Big)
$$

Таким образом данная версия метода токенизации на основе сингулярного разложения позволяет решить проблему требования фиксированного размера изображения, поскольку динамическая переменная присутствует только в длине последовательности. Единственное требование к размеру изображения - кратность 16. Также, данная версия позволяет решить проблему отсутствия оптимизации вычисления на видеокарте, поскольку она полностью реализована с помощью слоёв нейронных сетей, оптимизированных для вычисления на графических ускорителях во всех популярных библиотеках глубокого обучения. 

Стоит отметить, что в отличие от исходного метода токенизации на основе сингулярного разложения, данный метод токенизации не выполняет фильтрацию токенов входной последовательности трансформера ни в каком виде. Из-за этого длина последовательности токенов, получаемой данным токенизатором при обработке изображения равна длине последовательности токенов, получаемом при использовании токенизатора Vision Transformer.

К итоговой последовательности токенов добавляется токен класса и позиционное кодирование, аналогичное позиционному кодированию в оригинальной модели Trasnformer.

Данная версия токенизатора названа mSVD.

\subsection{Построение функции оценки}
Для фильтрации токенов входной последовательности была добавлена функция оценки токенов. Функция оценки токенов формирует оценку ``важности`` токена. Данная функция реализована с помощью многослойной нейронной сети.

Для обучения функции оценки, вычисляемая оценка умножается на соотвествующий токен. Это позволяет градиентам при обучении достигать весов функции оценки. Однако, без дополнительных изменений, функция оценки будет выдавать одно и то же значение. Для эффективного обучения функции оценки необходим вспомогательная функция потерь.

\subsubsection{Вспомогательная функция потерь на основе индекса Джини}
Предполагая, что оценка токена - величина положительная, к выходу функции оценки применяется функция активации Rectified Linear Unit (ReLU). 

$$
\text{ReLU}(x) = \dfrac{x + |x|}{2}
$$

Если без обучения функция оценки дает одинаковые оценки всем токенам, то необходимо штрафовать нейроную сеть за одинаковые оценки. Для этого можно использовать такую меру неоднородности, как индекс (коэффициент) Джини.

Коэффициент Джини для непрерывных элементов вычисляется следующим образом:

$$
G(x) = \dfrac{\sum\limits_{i=1}^n\sum\limits_{j=1}^n|x_i - x_j|}{2n^2\bar x}
$$

здесь $x_i$ - элемент последовательности, $n$ - длина последовательности, совпадает с количеством токенов, $\bar x$ - среднее значение элементов последовательности.

Поскольку $G(x) = 0$ при совпадении всех элементов последовательности $x$, то функция потерь, основанная на индексе Джини, выглядит следующим образом:

$$
L_G(x) = \beta(1 - G(x)),
$$

где $\beta$ - коэффициент вспомогательной функции потерь.

\subsubsection{Вспомогательная функция потерь на основе регуляризации шлюзов}

Выход функции оценки обрабатывается с помощью функции активации сигмоида

$$
\sigma(x) = \dfrac{1}{1 + e^{-x}}
$$

Полученные оценки назовём шлюзами $g_i = \sigma(x_i)$. Шлюзы могут принимать значения от 0 до 1. Для обучения функции оценки, каждый токен последовательности умножается на соответствующий ему шлюз. Это позволяет градиентам при обучении доходить до функции оценки. 

В случае, если значение шлюза близко к нулю, то после умножения на него, соответствующий токен становится близок к нулю и оказывает меньшее влияние на результат предсказания нейронной сети. В случае, если значения шлюза близко к единице, то соответствующий токен почти не изменяется при обучении.

Для того, чтобы функция оценок не обучилась таким образом, чтобы ``пропускать`` все токены (то есть предсказывать все значения шлюзов близкими к единице), в качестве вспомогательного лосса используется регуляризация шлюзов:

$$
L_g = \alpha \dfrac{1}{n}\sum_{i=1}^n g_i,
$$

где $\alpha$ - коэффициент вспомогательной функции потерь.

\subsubsection{Метод фильтрации токенов}
После получения оценок выполняется фильтрация токенов. Подобно предыдущим методам, можно выделить статический метод фильтрации и динамический.

Статический метод фильтрации заключается в отборе $k$ лучших токенов по их оценкам. В этом случае после добавления позиционного кодирования к последовательности токенов изначальной длины, по оценкам отбираются $k$ лучших токенов. Таким образом, длина новой последовательности равна $k$.

Динамический метод фильтрации заключается в вычислении суммы оценок токенов (или шлюзов) и отборе наименьшего количества токенов, сумма оценок которых не меньше доли $p$ от общей суммы оценок. В случае, если в одном минибатче получаются различные значения длины последовательности, из них выбирается максимальная.

Благодаря наличию функции оценки токенов, при обучении нейронной сети с методом $mSVD$-токенизации можно не использовать фильтрацию. При этом во время работы нейронной сети в режиме предсказания, можно изменять гиперпараметры применяемых методов фильтрации. Так, для одного избражения возможно применение статического метода фильтрации, а для другого - динамического без необходимости переобучения исходной нейронной сети.


\subsection{Результаты обучения}

\subsubsection{Обучение модели с mSVD токенизатором без функции оценки}

При обучении модели с рассматриваемым токенизатором (mSVD) без функции оценки и фильтрации токенов, размер последовательности токенов совпадает с размером последовательности при использовании токенизации Vision Transformer с размером патча 16. 

Результаты обучения представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с использованием mSVD-токенизатора и модели Vision Transformerr}
  \label{tab:msvd-tokenization-no-scorer}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Длина \\ входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ \hline
  \end{tabular}
\end{table}

При использовании данного метода токенизации получается достигнуть более высоких значений метрик, уменьшив количество неверно определенных классов на четверть.

\subsubsection{Обучение модели с mSVD токенизатором cо вспомогательной функцией потерь на основе индекса Джини}

Для фильтрации токенов используется динамический метод фильтрации при доле $p=0.900$.

Результаты обучения представлены в таблице.

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с использованием mSVD-токенизатора и модели Vision Transformer}
  \label{tab:msvd-tokenization-gini}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя \\ длина входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ 
    \makecell{mSVD (Джини, $\beta=1.0$)} & 0.82 & 0.82 & 231.4 \\
    \makecell{mSVD (Джини, $\beta=0.5$)} & 0.82 & 0.82 & 231.3 \\
    \makecell{mSVD (Джини, $\beta=0.1$)} & 0.82 & 0.82 & 231.3 \\
    \hline
  \end{tabular}
\end{table}

Получены одинаковые результаты для разных значений параметр $\alpha$. Это означает, что вспомогательная функция потерь на основе коэффициента Джини не оказывает никакого влияния на результат обучения модели. 

Также, об этом может свидетельствовать средняя длина входной последовательности. Можно заметить, что $231.4 = p \cdot 256 + 1$. Таким образом, функция оценки дает приблизительно одинаковые значения для любых токенов последовательности. Это означает, что функция потерь на основе индекса Джини неработоспособна.

Несмотря на это, итоговая модель все равно превосходит по значениям метрик Vision Transformer, имея при этом меньшую длину входной последовательности на десятую часть.

\subsubsection{Обучение модели с mSVD токенизатором cо вспомогательной функцией потерь на основе регуляризации шлюзов}

Фильтрация токенов отсутствует, результаты обучения представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение результатов обучения моделей с использованием mSVD-токенизатора и модели Vision Transformer}
  \label{tab:msvd-tokenization-sigmoid-gating}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Длина \\ входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ 
    \makecell{mSVD ($\alpha = 0.0250$)} & 0.83 & 0.83 & 257 \\ 
    \makecell{mSVD ($\alpha = 0.0125$)} & 0.85 & 0.85 & 257 \\
    \makecell{mSVD ($\alpha = 0.0050$)} & 0.85 & 0.84 & 257 \\
    \hline
  \end{tabular}
\end{table}

Лучшие результаты обучения были получены при значении $\alpha = 0.0125$. По итогу этого эксперимента, данное значение параметра выбирается по умолчанию для последующих экспериментов. 

Можно заметить, что лучшие значения метрик при обучении рассматриваемого метода токенизации с использованием функции оценки не превосходят значения метрик при обучении метода токенизации без использования функции оценки. Это ожидаемый результат, поскольку функция оценки никак не добавляет дополнительной информации при обработке изображения.

\subsubsection{Сравнение статического и динамического методов фильтрации токенов}

Результаты обучения представлены в таблице:

\begin{table}[H]
  \centering
  \caption{Сравнение статического и динамического методов фильтрации токенов}
  \label{tab:msvd-tokenization-static-dynamic}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя \\ длина входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ 
    \hline
    \makecell{mSVD (k=1)} & 0.43 & 0.40 & 2 \\ 
    \makecell{mSVD (k=4)} & 0.52 & 0.48 & 5 \\
    \makecell{mSVD (k=16)} & 0.61 & 0.57 & 17 \\
    \makecell{mSVD (k=32)} & 0.66 & 0.63 & 33 \\
    \makecell{mSVD (k=64)} & 0.71 & 0.70 & 65 \\
    \makecell{mSVD (k=96)} & 0.76 & 0.75 & 97 \\
    \makecell{mSVD (k=128)} & 0.80 & 0.80 & 129 \\
    \makecell{mSVD (k=160)} & 0.83 & 0.83 & 161 \\
    \makecell{mSVD (k=192)} & 0.85 & 0.85 & 193 \\
    \makecell{mSVD (k=224)} & 0.85 & 0.85 & 225 \\
    \hline
    \makecell{mSVD (p=0.100)} & 0.62 & 0.58 & 23.1 \\
    \makecell{mSVD (p=0.200)} & 0.67 & 0.64 & 46.6 \\
    \makecell{mSVD (p=0.300)} & 0.71 & 0.69 & 70.0 \\
    \makecell{mSVD (p=0.400)} & 0.74 & 0.73 & 90.4 \\
    \makecell{mSVD (p=0.500)} & 0.77 & 0.77 & 120.2 \\
    \makecell{mSVD (p=0.600)} & 0.81 & 0.81 & 149.4 \\
    \makecell{mSVD (p=0.700)} & 0.83 & 0.83 & 166.0 \\
    \makecell{mSVD (p=0.800)} & 0.85 & 0.85 & 192.5 \\
    \makecell{mSVD (p=0.900)} & 0.85 & 0.85 & 228.9 \\
    \makecell{mSVD (p=0.950)} & 0.85 & 0.85 & 242.2 \\
    \makecell{mSVD (p=0.990)} & 0.85 & 0.85 & 253.6 \\
    \hline
  \end{tabular}
\end{table}

Видно, что с помощью методов фильтрации на основе оценок токенов возможно сократить длину последовательности на четверть и не потерять в качестве работы модели. При этом, если сократить длину последовательности в два раза, то значения метрик все равно будут выше, чем при использовании Vision Transformer.

\section{Сравнение предложенных алгоритмов токенизации изображений и существующих решений}
\subsection{Токенизация изображений на основе Вейвлет-преобразования}
В работе \cite{wavelet_autoregression}, где предложен метод токенизации изображений на основе Вейвлет-преобразования, основная цель метода - авторегрессионная генерация изображения. Однако, данный метод может быть адаптирован и для других задач, связанных с обработкой изображений. Например, для решения задачи многоклассовой классификации.

Однако, применить данный метод для обработки изображений размерности больше, чем (3, 32, 32) не вышло, поскольку длина последовательности токенов становится равной нескольким тысячам. Это приводит к серьезной нехватке памяти и значительно снижает скорость обработки данных.

\subsection{Результаты обучения и сравнение с предложенными методами}

Лучшие результаты по всем рассмотренным методам были сведены в единую таблицу. В качестве FFT-токенизатора выбран токенизатор с размером статического фильтра 256, в качестве SVD-токенизатора выбран токенизатор с долей сохраненной информации равной 0.90, в качестве mSVD токенизатора был выбран токенизатор с динамической фильтрацией токенов с долей от суммы оценок равной 0.800.

\begin{table}[H]
  \centering
  \caption{Сравнение построенных токенизаторов с токенизатором на основе Вейвлет-преобразования и Vision Transformer}
  \label{tab:comparison}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя \\ длина входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{Вейвлет-токенизатор} & 0.50 & 0.43 & 1025 \\
    \makecell{FFT-токенизатор} & 0.79 & 0.79 & 257 \\
    \makecell{SVD-токенизатор} & 0.69 & 0.69 & 15.3 \\
    \makecell{mSVD} & 0.85 & 0.85 & 192.5 \\ 
    \hline
  \end{tabular}
\end{table}


\s\chapterconclusion

В результате исследования алгоритмов токенизации изображений на основе матричных разложений были построены рабочие методы токенизации на основе быстрого преобразования Фурье и сингулярного разложения. Однако, данные методы обладают серьезными недостатками, такими как ухудшение качества работы итоговой модели по сравнению с Vision Transformer и медленное вычисление матричных разложений, не оптимизированных для работы на видеокартах. 

Попытка решить эти недостатки привела к созданию метода токенизации mSVD, сохранившего преимущества Vision Transformer, такие как возможность параллельного вычисления и возможность обработки, и добившегося более высокой точности работы итоговой модели при меньшей длине входной последовательности. 


\end{document}