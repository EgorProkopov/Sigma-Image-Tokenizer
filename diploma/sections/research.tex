\section{Исследование алгоритмов токенизации изображений на основе матричных разложений}

Для создания способа токенизации, способного решить проблемы существующих методов, возможно использование различных алгоритмов преобразования и разложения матриц. В этой главе представлено исследование таких методов, как сингулярное разложение и преобразование Фурье, а также сравнение построенных алгоритмов с существующими.

\subsection{Построение инфраструктуры для исследования алгоритмов токенизации на основе матричных разложений}

Для проверки гипотезы о работоспособности построенных токенизаторов решалась задача многоклассовой классификации изображений. Набор данных, используемый для обучения - Intel Image Classification Dataset \cite{intel_image_dataset}, представленных 17 тысячами изображений 6 классов: ``buildings`` (``здания``), ``forest`` (``лес``), ``glacier`` (``ледник``), ``mountain`` (``гора``), ``sea`` (``море``), ``street`` (``улица``). Примеры изображений из набора данных представлены на  \autoref{fig:intel-multiclass-all} .Набор данных состоит из семантически разнообразных и сбалансированных классов. Исходная выборка разбита на тренировочную выборку, состоящую из приблизительно 14 тысяч изображений, и на валидационную, состоящую из 3 тысяч изображений.


\begin{figure}[htbp]
  \centering
  % Первая строка
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/research/dataset/buildings.jpg}
    \caption{``buildings`` (``здания``)}
    \label{fig:intel-multiclass-buildings}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/research/dataset/forest.jpg}
    \caption{``forest`` (``лес``)}
    \label{fig:intel-multiclass-forest}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/research/dataset/glacier.jpg}
    \caption{``glacier`` (``ледник``)}
    \label{fig:intel-multiclass-glacier}
  \end{subfigure}

  \bigskip % или \\ для переноса

  % Вторая строка
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/research/dataset/mountain.jpg}
    \caption{``mountain`` (``гора``)}
    \label{fig:intel-multiclass-mountain}
  \end{subfigure}
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/research/dataset/sea.jpg}
    \caption{``sea`` (``море``)}
    \label{fig:intel-multiclass-sea}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/research/dataset/street.jpg}
    \caption{``street`` (``улица``)}
    \label{fig:intel-multiclass-street}
  \end{subfigure}

  \caption{Примеры изображений, представленных в используемом наборе данных}
  \label{fig:intel-multiclass-all}
\end{figure}


Все изображения считываются как трехканальные и масштабируются до размера 256, после чего нормализуются со следующими значениями среднего и стандартного отклонения \cite{torchvision_normalization}: 

$$
\mu = (0.485, 0.456, 0.406), \quad \sigma = (0.229, 0.224, 0.225)
$$

Для реализации предобработки данных изображений использовалась библиотека \texttt{torchvision.transforms}. Для избежания переобучения, использовалась случайная аугментация изображений, а именно:

\begin{itemize}
    \item Случайное обрезание до $0.8$ от размера изначального изображения,
    \item Случайный вертикальная симметрия изображения с вероятностью 0.5
\end{itemize}

При использовании моделей, требующих разбиения изображения на патчи, используется квадратный патч размером 16.

В качестве основной модели, используемой для извлечения и обработки признаков в токен класса используется модель Transformer со следующими параметрами архитектуры:

\begin{itemize}
    \item Размерность токена: 768,
    \item Количество слоев трансформера: 12,
    \item Количество голов внимания трансформера: 12,
    \item Скрытая размерность многослойного перцетрона внутри трансформера: 3072
\end{itemize}

Для классификации изображения по одному из представленных в наборе данных классу используется классификационная голова на основе многослойного перцептрона. Данный модуль на вход принимает значение токена класса. 

Многослойный перцептрон состоит из следующих слоев:

\begin{itemize}
    \item Линейный полносвязный слой с количеством входов, равным размерности токенов трансформера, и 128 выходами,
    \item Функция активации ReLU \cite{relu},
    \item Линейный полносвязный слой с количеством входов 128 и количеством выходов 6
\end{itemize}

Итоговая модель преобразует предобработанное изображение, используя следующую последовательность модулей:

\begin{itemize}
    \item Токенизатор изображения
    \item Модель трансформер
    \item Классификационная голова
\end{itemize}


% Нужна схема

Для построения модели и ее обучения использовались библиотеки  \texttt{torch} и \texttt{lightning.torch}.

Для обучения модели задачи многоклассовой классификации применяется функция потерь перекрестной энтропии \cite{goodfellow_dl}: 

$$
\mathcal{L}_{\mathrm{CE}}
= -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \,\log\bigl(\hat{p}_{i,c}\bigr),
$$

где: 

\begin{itemize}
  \item $N$ — число объектов в минибатче,
  \item $C$ — число классов,
  \item $y_{i,c}\in\{0,1\}$ — индикатор того, что $i$-й образец относится к классу $c$,
  \item $\hat{p}_{i,c}=\dfrac{e^{(z_{i,c})}}{\sum_{j=1}^Ce^{(z_{i,j})}}$ — предсказанная моделью вероятность класса $c$ для образца $i$ (применяется функция softmax по выходам $z_{i,*}$).
\end{itemize}

При обучении были применены следующие гиперпараметры:

\begin{itemize}
    \item Размер тренировочного батча: 12
    \item Скорость обучения: 0.0001
    \item Количество эпох: 20
\end{itemize}


Для отслеживания качества обучения модели рассматривались такие метрики, как точность

$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

и $F_1$-метрика

$$
F_\beta = (1 + \beta^2)\,\frac{\mathrm{Precision}\;\cdot\;\mathrm{Recall}}{\beta^2\,\mathrm{Precision} + \mathrm{Recall}}, \qquad  F_1 = 2 \cdot \frac{\text{Precision} \;\cdot\; \text{Recall}}{\text{Precision} + \text{Recall}},
$$

где:

\begin{itemize}
  \item $TP$ (True Positive) — число объектов положительного класса, правильно отнесённых к положительному классу.
  \item $TN$ (True Negative) — число объектов отрицательного класса, правильно отнесённых к отрицательному классу.
  \item $FP$ (False Positive) — число объектов отрицательного класса, ошибочно отнесённых к положительному классу.
  \item $FN$ (False Negative) — число объектов положительного класса, ошибочно отнесённых к отрицательному классу.
  \item $\text{Precision}$ (точность) — доля правильно классифицированных положительных объектов среди всех объектов, отнесённых к положительному классу

    $$
    \text{Precision} = \frac{TP}{TP + FP}.
    $$
  
  \item $\text{Recall}$ (полнота) — доля правильно классифицированных положительных объектов среди всех действительно положительных объектов

    $$
    \text{Recall} = \frac{TP}{TP + FN}.
    $$
\end{itemize}

Для всех дальнейших экспериментов была применена данная инфраструктура обучения моделей и измерения метрик на валидационной выборке.


\subsection{Токенизация изображений на основе быстрого преобразования Фурье}

\subsubsection{Анализ применения быстрого преобразования Фурье для токенизации изображений}

Рассмотрим черно-белое изображение $i(x, y)$ размера $(M, M)$. Двумерное дискретное преобразование Фурье \cite{gonzalez_woods} позволяет получить частотное представление изображения $I(u, v)$ как

$$
I(u, v) = \sum_{x=0}^{M-1}\sum_{y=0}^{M-1} i(x, y) e^{-i2\pi\Big(\dfrac{ux}{M} + \dfrac{vx}{M}\Big)}
$$

Поскольку вычислительная сложность алгоритма быстрого преобразования Фурье \cite{fft} составляет $O(M^2 \log(M^2))$ вместо $O((M)^4)$, при этом позволяя получить тот же самый результат, далее будет применяться именно этот алгоритм. 

$I(u, v)$ можно представить как изображение с комплекснозначной интенсивностью пикселей, либо же как двухканальное изображение. Для наглядности визуализации используется спект мощности, определяемый как 

$$
I^{power} = \sqrt{(Re(I))^2 + (Im(I))^2}
$$

Также, поскольку зачастую в спектрах мощностей присутствуют значительные пики (большие значения) малого количества частот, используется масштабирование спектра мощности

$$
\log(I^{power}) \quad \text{или} \quad \sqrt{I^{power}}
$$

В дальнейшем, при вычислении спектра мощности будет использоваться именно метод масштабирования на основе логарифма.

Также стоит отметить, что при визуализации или построении низкочастотного фильтра, используется центрированный спектр мощности. Поскольку в $I^{power}$ низким частотам соответствуют значения на краях, для удобства последующей обработки применяется центральная симметрия.

\subsubsection{Построение низкочастотного фильтра}

Поскольку высокие частоты содержат лишь малую долю информации, можно построить фильтр низких частот \cite{low_pass_filter}, отсекающий высокие частоты. Такой подход позволяет значительно сократить количество обрабатываемых данных при сохранении основной информации, а также позволяет очистить исходное изображение от шумов. Обычно, для построения такого фильтра используется отбор частот с помощью евклидовой расстояния до центра спектра мощности.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/solutions_analysis/fourier/low_pass_filter.png}
    \label{fig:svd_approx_im_fix_rank}
    \caption{Фильтр низких частот с использованием евклидова расстояния до центра спектра мощности.}
\end{figure}

В дальнейшем выход низкочастотного фильтра будет обрабатываться нейронной сетью. Однако, так как нейронные сети обрабатывают матрицы, использование конкретно данного фильтра приведет к тому, что в углах выхода низкочастотного фильтра будут находиться нули. В свою очередь, это приведет к лишним вычислениям и затратам памяти, не улучшающих итоговый результат работы модели. Также, это сократит объем полезной информации, используемой трансформером для обработки. Поэтому, для того, чтобы сохранить больше полезной информации, выполним отбор частот не с помощью расстояния Евклида

$$
d_{\mathrm{E}}(\mathbf{x}, \mathbf{y})
= \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2},
$$

а с помощью расстояния Чебышева

$$
d_{\mathrm{Ch}}(\mathbf{x}, \mathbf{y})
= \max_{1 \le i \le n} \bigl|x_i - y_i\bigr|.
$$

% нужна картинка низкочастотного фильтра с расстоянием Чебышева

Для обработки многоканальных (в том числе и цветных) изображений, представим их с помощью трёх матриц, к каждой из которых применим быстрое преобразование Фурье и низкочастотный фильтр по одинаковой маске. В результате получим тензор размерности (6, $s$, $s$), где $s$ - размер фильтра, то есть предельное расстояние (с использованием нормы Чебышева), при котором частоты сохраняются в результате отбора низкочастотного фильтра.

\subsubsection{Вычисление размера фильтра}
Размер фильтра может быть задан как фиксированный гиперпараметр. Такой фильтр назовем статическим фильтром.

Однако, в этом случае результат работы модели будет сильно отличаться в зависимости от размера входного изображения. Так, при обработке больших изображений, многократно больших, чем размер фильтра, будут отбираться только самые низкие частоты. В это же время, при обработке изображений, размер которых соответствует размеру фильтра или их размер меньше размера фильтра, будут учитываться абсолютно все частоты. Это делает вычисление размера фильтра важной задачей при построении токенизатора на основе быстрого преобразования Фурье.

Очевидно, что размер фильтра должен коррелировать с размером обрабатываемого изображения. Это делает размер фильтра $s$ динамически изменяемым параметром. Для определения $s$ воспользуемся центрированным отмасштабированным спектром мощности. Можно заметить, что низкие частоты имеют значительно большую интенсивность, чем высокие частоты. Сумму всех интенсивностей назовем энергией спектра мощности 

$$
E = \sum\limits_{i=-M/2}^{M/2}\sum\limits_{j=-M/2}^{M/2} I^{power}(i, j)
$$ 

Поскольку для построения токенизатора нам необходимы в первую очередь низкие частоты, будем увеличивать размер фильтра $s$ таким образом, пока доля охватываемой фильтром энергии спектра мощности не превысит $pE$, где $p \in (0, 1]$ - гиперпараметр, который назовем долей энергии спектра мощности.

Таким образом, значение $s$ можно вычислить с помощью условия

$$
\sum_{i=-s/2}^{s/2}\sum_{j=-s/2}^{s/2} I^{power}(i, j) \leq pE < \sum_{i=-\frac{s+1}{2}}^{\frac{s+1}{2}}\sum_{j=-\frac{s+1}{2}}^{\frac{s+1}{2}} I^{power}(i, j)
$$

Для вычисления значения $s$ в программе используются двумерные кумулятивные суммы.

Такой фильтр, размер которого вычисляется с помощью относительной энергии спектра мощности, назовем динамическим фильтром. 

Статический и динамический фильтры обладают следующими преимуществами и недостатками:

\begin{itemize}
    \item Размер статического фильтра всегда одинаков, соответственно, после токенизации, количество токенов входной последовательности трансформера будет неизменным. Это делает количество требуемых вычислительных ресурсов независимым от размера изображения. В свою очередь размер динамического фильтра зависит от размера входного изображения, что может привести к слишком большой длине входной последовательности при обработке изображений большого размера
    \item В отличие от статического фильтра, динамический фильтр позволяет более гибко отбирать частоты, поскольку размер фильтра зависит от того, что изображено на изображении. Так, если изображение состоит из слабоменяющихся, больших и однотонных элементов, то у такого изображения будут преобладать низкие частоты, а соответственно, размер фильтра будет меньше. Если на изображении преобладают высокие частоты, то размер фильтра будет больше.
\end{itemize}



\subsubsection{Построение токенизатора на основе низкочастотного фильтра}

Для построения токенизатора изображения на основе быстрого преобразования Фурье построим низкочастотный фильтр. Маску низкочастотного фильтра будем формировать на основе нормы Чебышева, поскольку в этом случае маска получается квадратная. В результате, цветное изображение размерности $(3, M, M)$ преобразуется в тензор размерности $(6, s, s)$. 

Были рассмотрены различные способы преобразования этого тензора в последовательность векторов.

Первый из рассмотренных способов - способ разбиения на патчи. Данный способ повторяет метод, предложенный в Vision Transformer, однако разбиение на патчи применяется не напрямую к изображению, а к выходу низкочастотного фильтра.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]
    {images/research/fourier/patches_split.png}
    \caption{Пример разбиения выхода низкочастотного фильтра на 4 патча.}
\end{figure}

После разбиения на патчи, каждый патч выпрямляется в вектор. Таким образом, тензор размерности 

$$ (6, s, s)$$ 

преобразуется в последовательность векторов размерности 

$$\Big(\dfrac{s^2}{s_p^2}, 6 \cdot s_p^2\Big)$$ 

где $s_p$ - размер одного патча. После этого преобразования каждый вектор полученной последовательности проецируется с помощью линейного полносвязного слоя, называемого слоем проекции, в пространство токенов трансформера. Эта проекция необходима, так как размерность векторов полученной последовательности может не совпадать с требуемой размерностью токенов для обработки их трансформером. 

В программе процесс разбиения изображения на патчи, их выравнивание и линейную проекцию линейным полносвязным слоем можно заменить на свёрточный слой нейронной сети с ядром свертки и шагом свертки равными размеру патча.

К полученной последовательности токенов добавляется токен класса и позиционное кодирование, аналогичное позиционному кодированию в Vision Transformer.

Вторым рассмотренным способом преобразования входного тензора в последовательность векторов является метод интервального разбиения. Результатом применения низкочастотного фильтра является карта признаков, отражающая не пространственные связи между фильтрами, а степень влияния различных частотных компонентов. Метод разбиения на интервалы позволяет сгруппировать эти компоненты по частотным интервалам. Это в свою очередь позволяет модели трансформера в дальнейшем, при обработке входного тензор, выделить наиболее значимые частотные диапазоны. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]
    {images/research/fourier/bins_split.png}
    \caption{Пример разбиения выхода низкочастотного фильтра на 4 интервала.}
\end{figure}

В этом подходе выход низкочастотного фильтра разбивается на $n_b$ ``полос`` - интервалов. Количество интервалов $n_b$ - гиперпараметр. Каждый такой интервал выпрямляется в вектор. Таким образом, исходный тензор размерности 

$$
(6, s, s) 
$$

преобразуется в последовательность векторов размерности

$$
\Big(n_b, \dfrac{s^2}{n_b}\Big)
$$

Каждый вектор полученной последовательности проецируется с помощью линейного полносвязного слоя в в пространство токенов трансформера. Аналогично методу с разбиением на патчи, эта проекция необходима для приведения полученных векторов к размерности, которую возможность обработать трансформером.

К полученной последовательности токенов добавляется токен класса и позиционное кодирование, аналогичное позиционному кодированию в оригинальной модели Transformer. 

Данный способ разбиения входного тензора на интервалы обладает существенными недостатками. Так, его применение возможно только при использовании статического фильтра низких частот, так как в случае использования динамического фильтра, размер фильтра $s$ - также динамический. Это значит, что последовательность векторов, полученная после разбиения на интервалы выхода низкочастотного фильтра, состоит из векторов динамической размерности $\dfrac{s^2}{n_b}$. Это делает невозможным их проекцию в пространство фиксированной размерности с помощью линейного полносвязного слоя. Данный недостаток существенен, поскольку лишает итоговый токенизатор гибкости при фильтрации токенов.

Поскольку метод разбиения на патчи не обладает недостатками, которыми обладает метод разбиения на интревалы, рассмотрим способы его углубления. Как ранее было отмечено, процесс разбиения изображения на патчи, а при построении токенизатора на основе быстрого преобразования Фурье - выхода низкочастотного фильтра, можно заменить на свёрточный слой с размером свёртки и шагом свертки, равным размеру патча.

Важно отметить, что один свёрточный слой с ядром свёртки размером 5, шагом 1, отступом 1 и без использования нейрона смещения может быть заменен \cite{conv_replace} двумя свёрточными слоями с ядром свёртки размером 3, шагом 1, отступом 1 и также без использования нейрона смещения. В этом случае область, которую обрабатывают эти слои за один шаг остается той же, при этом между двумя свёрточными слоями можно добавить больше функций активации, что позволит итоговой нейронной сети аппроксимировать гораздо более сложные функции. При этом уменьшится количество параметров: при использовании свёрточного слоя с ядром свёртки размером 5, количество параметров на одно ядро становится равным 25, а при использовании двух слоёв с ядром свёртки размером 3, эквивалентное количество параметров равно 18. 

Данный процесс ``разложения`` свёрточных слоёв на свёрточные слои с ядрами свёртки размером 3 можно применить и для свёрточных слоёв с размерами ядер свёртки 15 и 17 (что близко к размеру ядра свёртки 16 - наиболее часто используемому размеру патча). Например, свёрточный слой с размером ядра свёртки 15 можно разложить на последовательность из 7 свёрточных слоёв с размером ядра свёртки 3, а свёрточный слой с размером ядра свёртки 17 можно разложить на 8 свёрточных слоев с размером ядра свёртки 3. 

Однако, в этом случае не получится изменить размер шага свёртки. Из-за этого, после применения такой последовательности свёрточных слоёв с размером ядра свёртки 3, не изменится размер карт признаков. Однако при этом, количество карт признаков увеличится.

Таким образом, исходный тензор размерности

$$(6, s, s)$$

будет преобразован в тензор размерности 

$$
(s_E, s, s),
$$

где $s_E$ - размерность токенов трансформера. Очевидно, что количество обрабатываемых данных вырастет многократно, при этом количество полезной информации нисколько не изменится. 

Для уменьшения размерности карт признаков при обработке изображений свёрточными нейронными сетями часто используют слои объединения (пулинга) \cite{goodfellow_dl}. Эти слои позволяют уменьшить размерность карт признаков, пожертвовав частью информации. Этот подход не удовлетворителен, так как потеря информации приведет к ухудшению качества работы итоговой модели. 

Вместо этого, рассмотрим нейронную сеть Super Resolution Generative Adversarial Network (SRGAN) \cite{srgan}. Это генеративная соревновательная нейронная сеть, созданная специально для решения задачи повышения разрешения изображения. В этой модели, для получения карт признаков большей размерности, используется алгоритм пиксельного перемешивания (pixel shuffle). Данный алгоритм группирует карты признаков по 4, после чего объединяет их в одну карту признаков с размером в 2 раза больше по длине и по ширине. В ходе объединения, элементы с одних и тех же позиций разных карт признаков объединяются в квадраты размером 2 на 2 с сохранением исходных позиций. Данный алгоритм позволяет изменить форму обрабатываемых данных, никак не меняя сами данные.

Поскольку текущая задача противоположная, применим алгоритм пиксельной расстановки (pixel unshuffle) - операцию, обратную алгоритму пиксельного перемешивания. В этом случае одну карту признаков будем разбивать на 4 карты с уменьшением исходной длины и ширины в 2 раза. 

В итоге, для того, чтобы заменить свёрточный слой с ядром свёртки размером 16 и шагом 4, применим после каждого свёрточного слоя c ядром свёртки размером 3 и функции активации алгоритм пиксельной расстановки. Количество таких блоков определяется размером заменяемого патча. В случае с размером патча 16, количество таких блоков равно 4, так как $2^4 = 16$. Поскольку в этом случае от размера выхода низкочастотного фильтра требуется кратность 16, рассчитанный размер фильтра округляется в большую сторону до первого значения, кратного 16.


Таким образом, исходный тензор размерности

$$
(6, s, s)
$$

преобразуется в тензор размерности

$$
\Big(s_E, \dfrac{s}{16}, \dfrac{s}{16}\Big)
$$

Данный тензор выпрямляется по двум последним осям и транспонируется. Следом каждый вектор последовательности проецируется с помощью полносвязного линейного слоя с количеством входов и количеством выходов, равными размерности токена. После этого получается последовательность векторов --- токенов, готовых к обработке моделью трансформер. Такая последовательность имеет форму.

$$
\Big(\dfrac{s^2}{16^2}, s_E\Big)
$$


Итоговая схема изображена на \autoref{fig:mfft-scheme}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/research/fourier/mfft_scheme.png}
    \caption{Схема токенизатора на основе быстрого преобразования Фурье.}
    \label{fig:mfft-scheme}
\end{figure}

\subsubsection{Результаты обучения}

Во время обучения моделей с токенизатором на основе быстрого преобразования Фурье не использовалась нормализация изображений кроме отдельно рассмотренного эксперимента.

Было проведено сравнение методов токенизации с использованием быстрого преобразования Фурье. Результаты обучения представлены в \autoref{table:fft-tokenization}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|}
    \hline
    Метод токенизации & Точность & $F_1$-метрика \\ \hline
    Vision Transformer & 0.79 & 0.79  \\
    FFT-токенизация (патчи) & 0.16 & 0.16  \\ 
    FFT-токенизация (интервалы)  & 0.17 & 0.17  \\ 
    FFT-токенизация (пиксельное перемешивание) & 0.79 & 0.79 \\
    \hline
  \end{tabular}
    \caption{Сравнение результатов обучения моделей с различными токенизаторами на основе быстрого преобразования Фурье с моделью Vision Transformer.}
  \label{table:fft-tokenization}
\end{table}

Из результатов обучения \autoref{table:fft-tokenization} видно, что из всех рассмотренных методов токенизации, единственным работоспособным оказался только метод токенизации с использованием пиксельного перемешивания. Поэтому следующие эксперименты были проведены только с использованием этого метода.

Далее было проведено сравнение методов токенизации с использованием низкочастотного и высокочастотного фильтров. Был исследован метод токенизации, аналогичный рассмотренному ранее, только с использованием высокочастотного фильтра вместо низкочастотного. Для построения высокочастотного фильтра не применялась центральная симметрия результата работы алгоритма быстрого преобразования Фурье. Было проведено сравнение при различных значениях размера статического фильтра. Результаты обучения и замера метрик представлены в \autoref{tab:fft-tokenization-unshifted}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    Метод токенизации & Размер фильтра & Точность & $F_1$-метрика \\ \hline
    Низкочастотный фильтр & 256 & 0.79 & 0.79 \\
    Высокочастотный фильтр & 64 & 0.32 & 0.25 \\
    Высокочастотный фильтр & 128 & 0.51 & 0.51 \\
    Высокочастотный фильтр & 256 & 0.79 & 0.79 \\
    \hline
  \end{tabular}
    \caption{Сравнение результатов обучения моделей с токенизатором с высокочастотным фильтром при разных размерах фильтра с токенизатором с низкочастотным фильтром.}
  \label{tab:fft-tokenization-unshifted}
\end{table}

Из \autoref{tab:fft-tokenization-unshifted} видно, что низкие частоты оказывают значительное влияние на итоговое качество работы модели, что подтверждает изначальную гипотезу о их важности при обучении нейронной сети. Также можно заметить, что модель с токенизатором с высокочастотным фильтром и малым размером фильтра, несмотря на серьезное падение значений метрик, работоспособна.

Также было выполнено сравнение размеров статического низкочастотного фильтра и проведено исследование их влияния на результат обучения модели. Результаты обучения и замера метрик представлены в \autoref{tab:fft-tokenization-static}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    Метод токенизации & Размер фильтра & Точность & $F_1$-метрика \\ \hline
    Vision Transformer & - & 0.79 & 0.79 \\
    Низкочастотный фильтр & 64 & 0.76 & 0.76 \\
    Низкочастотный фильтр & 128 & 0.78 & 0.78 \\
    Низкочастотный фильтр & 256 & 0.79 & 0.79 \\
    \hline
  \end{tabular}

    \caption{Сравнение результатов обучения моделей с токенизатором с низкочастотным фильтром при разных размерах статического фильтра.}
  \label{tab:fft-tokenization-static}
\end{table}

Из \autoref{tab:fft-tokenization-static} видно, что серьезное уменьшение размера фильтра (в 4 раза) привело к лишь незначительному снижению качества работы модели как по сравнению с моделью с размером фильтра, равным размеру изображения, так и по сравнению с Vision Transformer. Важно также заметить, что уменьшение размера фильтра в 4 раза привело к уменьшению размера входной последовательности токенов для обработки трансформером в 16 раз. 

Далее было проведено исследование влияния сохраняемой доли энергии спетра мощности на обучение модели. Результаты обучения и замера метрик представлены в \autoref{tab:fft-tokenization-dynamic}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    Метод токенизации & Размер фильтра & Точность & $F_1$-метрика \\ \hline
    Vision Transformer & - & 0.79 & 0.79 \\
    Низкочастотный фильтр (0.900) & 96 & 0.74 & 0.74 \\
    Низкочастотный фильтр (0.950) & 128 & 0.76 & 0.76 \\
    Низкочастотный фильтр (0.990) & 208 & 0.77 & 0.76 \\
    \hline
  \end{tabular}

    \caption{Сравнение результатов обучения моделей с токенизатором с низкочастотным фильтром при разных размерах динамического фильтра (значение сохраняемой доли энергии указано в скобках возле названия метода токенизации)}
  \label{tab:fft-tokenization-dynamic}
\end{table}

Из \autoref{tab:fft-tokenization-dynamic} видно, что заметно не сильное падение значений метрик при значительном уменьшении размера фильтра. Также, если сравнивать результаты обучения с использованием динамического фильтра и с использованием статического фильтра, можно заметить, что при одинаковых размерах фильтра, при использовании динамического фильтра значения метрик оказываются немногим ниже, чем при использовании статического фильтра. Вероятно, на это повлияла динамическая длина последовательности при обучении модели.

Также, было важным провести исследование влияния нормализации изображений на работу токенизатора.

Нормализация изображений - простое афинное преобразование, которое приближает значения пикселей к стандартному нормальному распределению и выравнивает статистики RGB-каналов изображения. Данный метод предобработки изображений делает процесс обучения нейронной сети более быстрым, стабильным и надёжным \cite{goodfellow_dl}. Отсутствие нормализации замедляет обучение модели.

Однако, применение нормализации изображений может привести к потери части информации о низких частотах и исказить относительные амплитуды.

Было проведено исследование влияния нормализации изображений на обучение модели с токенизатором на основе быстрого преобразования Фурье. Результаты обучения и замера метрик представлены в \autoref{tab:fft-tokenization-norm}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    Нормализация & Размер фильтра & Точность & $F_1$-метрика \\ \hline
    Присутствует & 128 & 0.48 & 0.48 \\
    Отсутствует & 128 & 0.78 & 0.78 \\
    \hline
  \end{tabular}

    \caption{Сравнение результатов обучения моделей при наличии и отсутствии нормализации изображений во время обучения.}
  \label{tab:fft-tokenization-norm}
\end{table}

Как видно из \autoref{tab:fft-tokenization-norm}, нормализация изображений очень негативно влияет на результаты обучения моделей с использованием токенизатора на основе быстрого преобразования Фурье. Происходит падение точности почти в два раза. Таким образом, можно сделать вывод, что при обучении моделей с использованием данного токенизатора, использование нормализации изображений нежелетельно.

\subsection{Токенизация изображений на основе сингулярного разложения}

\subsubsection{Анализ применения сингулярного разложения для токенизации изображений}

Сингулярное разложение \cite{loginov_svd} матрицы $I$ размерности $(M, N)$ --- разложение вида 

$$
I = U\Sigma V^*,
$$

где $\Sigma$ --- диагональная матрица сингулярных чисел размерности $(M, N)$, $U$ --- матрица размерности $(M, M)$, $V$ - матрица размерности $(N, N)$, а $V^*$ - эрмитово-сопряженная матрица матрицы $V$. Матрицы $U$ и $V$ - матрицы левых и правых сингулярных векторов соответственно. Сингулярные числа неотрицательны. Поскольку рассматривается применение сингулярного разложения только для токенизации изображений, то есть вещественных матриц, то $V^* = V^T$.

Компонентой сингулярного выражения назовем сингулярное число и соответствующие ему левый и правый сингулярные вектора.

По свойствам сингулярного произведения, можно одновременно переставлять соответствующие столбцы матриц $U$ и $V$ вместе с диагональными элементами, не меняя результата произведения. Для дальнейшего удобства, переставим компоненты сингулярного разложения в порядке убывания сингулярных чисел.

\subsubsubsection{Приближение изображения с помощью сингулярного разложения при фиксированном ранге}

По теореме Эккарта-Янга\cite{eckart_young}, если требуется приблизить матрицу $I$ другой матрицей $I_k$ с заранее заданным рангом $k$ (рангом приближения), чтобы значение $||I - I_k||_2^2$ было минимальным, то наилучшая такая матрица получается из сингулярного разложения матрицы $I$ по формуле:

$$
I_k = U_k\Sigma_kV_k^T
$$

где $\Sigma_k$ - матрица $k$ первых (наибольших) сингулярных чисел, а матрицы $U$ и $V$ состоят из соответствующих им сингулярных векторов. Таким образом можно приблизить матрицу $I$ по заданному рангу. 

Представим цветное трехканальное изображение (для упрощения будем рассматривать только квадратные изображения) как набор трех матриц. Тогда, выполнив приближение каждой из этих матриц по выбранному рангу $k$, можно получить приближение исходного изображения.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/solutions_analysis/svd/svd_approx_im_160rank.png}
    \caption{Сравнение исходного изображения (размером 256 на 256 пикселей) и приближения сингулярным разложением по рангу 160.}
    \label{fig:svd-approx-im-fix-rank}
\end{figure}

Из \autoref{fig:svd-approx-im-fix-rank} видно, что при приближении изображения сингулярным разложением нет потери визуальной информации.

При этом, если выбрать сингулярное разложение как основу для токенизации изображений, а компоненты сингулярного разложения представить в виде этих самых токенов, то такое приближение позволит уменьшить длину входной последовательности с 256 до 160.

\subsubsection{Приближение изображения с помощью сингулярного разложения при динамическом ранге}

При решении задачи приближения некоторой матрицы матрицей меньшего ранга с помощью сингулярного разложения, сингулярные значения, возведенные в квадрат, можно интерпретировать как дисперсию, которую ''вкладывает'' в итоговый результат каждая компонента. Причем, чем больше значение сингулярного числа, тем большей части информации оно соответствует. 

Поскольку в общем случае изображения могут сильно отличаться друг от друга, и в одном примере для сохранения большей части информации потребуется только, например, 5 первых компонент, а в другом --- больше 100, то для создания токенизатора на основе сингулярного изображения необходим динамический выбор ранга $k$ приближения изображения.   

Поэтому можно вычислить ранг $k$ так, чтобы

$$
    \sum_{i=1}^{k} \sigma_i^2 <= p\sum_{i=1}^{im\_size} \sigma_i^2 < \sum_{i=1}^{k+1} \sigma_i^2,
$$

где $M$ - размер изображения, а $p$ - доля сохраняемой информации, настраиваемый гиперпараметр.

Однако, настройка гиперпараметра $p$ может быть слишком чувствительной при вычислении ранга $k$ с использованием квадратов сингулярных чисел, как видно из \autoref{fig:svd_lin_vs_square}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/solutions_analysis/svd/svd_lin_vs_square.png}
    \caption{Сравнение зависимости доли сохраняемой информации изображения от ранга приближения.}
    \label{fig:svd_lin_vs_square}
\end{figure}

Для более удобной настройки гиперпараметра $p$, будем вычислять ранг $k$ следующим образом:

$$
    \sum_{i=1}^{k} \sigma_i <= p\sum_{i=1}^{im\_size} \sigma_i < \sum_{i=1}^{k+1} \sigma_i,
$$

\subsubsection{Построение токенизатора на основе сингулярного разложения}

Для построения токенизатора изображений на основе сингулярного разложения будем использовать приближение изображения по динамическому рангу с линейной суммой сингулярных чисел.

Перепишем разложение матрицы $I_k$:

$$
I_k = U_k\Sigma_kV_k^T = (U_k\sqrt{\Sigma_k})(\sqrt{\Sigma}V_k^T) = U'V'^T
$$

Таким образом получаем матрицы $U'$ и $V'$. Для разбиения на исходной матрицы на набор векторов, разобьем матрицы $U'$ и $V'$ на наборы векторов $u_1, u_2, u_3, \cdots$ и $v_1, v_2, v_3, \cdots$, после чего попарно объединим вектора $u_i$ и $v_i$ в один вектор (выполним операцию конкатенации векторов).

Поскольку рассматривается токенизация трехканальных цветных изображений, то такое разбиение выполняется для каждого канала по отдельности. После чего полученные векторы объединяются в один.

$$
t = \text{concat}(u_{i1}, v_{i1}, u_{i2}, v_{i2}, u_{i3}, v_{i3}),
$$

где $\text{concat()}$ - операция конкатенации векторов, а $u_{i1}, v_{i1}, u_{i2}, v_{i2}, u_{i3}, v_{i3}$ - вектора, соответсвующие $i$-столбцам матриц $U'$ и $V'$ каждого из трех каналов исходного изображения.

Полученный набор векторов преобразуется с помощью линейного полносвязного слоя, слоя проекции, в размерность пространства токенов трансформера. При таком разбиении, исходный тензор размерности

$$
(3, M, M)
$$

преобразуется в последовательность токенов размерности

$$
(k, s_E)
$$

Стоит учесть, что поскольку ранг вычисляется динамически, то при обработке в программе одного минибатча для каждого изображения может быть вычислен различный ранг. В этом случае, выбирается максимальный ранг для всех изображений.

К полученной последовательности добавляется токен класса и позиционное кодирование, аналогичное используемому в модели Transformer.

\subsubsection{Результаты обучения}

Сначала было проведено сравнение обучения модели с токенизацией на основе сингулярного разложения с Vision Transformer. Для обучения был построен токенизатор на основе сингулярного разложения с использованием динамического ранга аппроксимации.

Результаты обучения и представлены в \autoref{tab:svd-tokenization}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя длина \\ входной последовательности} \\ 
    \hline
    Vision Transformer & 0.79 & 0.79 & 257 \\
    SVD-токенизация & 0.69 & 0.69 & 15.3 \\ \hline
  \end{tabular}
    \caption{Сравнение результатов обучения моделей с токенизатором на основе сингулярного разложения (SVD) с моделью Vision Transformer}
  \label{tab:svd-tokenization}
\end{table}

При обучении модели доля сохраненной информации токенизатором на основе сингулярного разложения была выбрана $p = 0.900$.

Из результатов, представленных в \autoref{tab:svd-tokenization}, видно, что метод токенизации на основе сингулярного разложения работоспособен. Причем, несмотря на небольшое падение значений метрик, удалось значительно сократить длину входной последовательности.

В \autoref{tab:svd-tokenization-disp} приведено сравнение результатов обучения модели с токенизатором на основе сингулярного разложения при различных значениях гиперпараметра доли сохраненной информации.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации}
      & \makecell{Доля \\ сохраненной \\ информации}
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя длина \\ входной \\ последовательности} \\ 
    \hline
    SVD-токенизация & 0.90 & 0.69 & 0.69 & 15.3 \\
    SVD-токенизация & 0.95 & 0.64 & 0.64 & 89.1 \\
    SVD-токенизация & 0.99 & 0.67 & 0.67 & 159.7 \\ \hline
  \end{tabular}
  
  \caption{Сравнение результатов обучения моделей с токенизатором на основе сингулярного разложения при разных значениях доли сохраненной информации}
  \label{tab:svd-tokenization-disp}
\end{table}

Получены контринтуитивные результаты, при которых большая доля сохранения информации приводит к падению метрик на этапе валидации. Вероятно, это вызвано тем, что большая динамическая длина последовательности приводит к ухудшению обучения модели.

\subsubsection{Проблемытокенизатора на основе сингулярного разложения}

Текущая версия токенизатора имеет следующие проблемы:

\begin{enumerate}
    \item Падение метрик даже при большой доли сохраненной информации.
    
        Несмотря на большую долю сохраненной информации и длину входной последовательности, полученные метрики оказались хуже. Это может свидетельствовать о том, что некоторые из компонент сингулярного разложения оказывают негативное влияние на результат работы нейронной сети.
    \item Требование к фиксированному размеру изображений.
    
        Поскольку в текущей версии токенизатора размерность изображения напрямую влияет на количество параметров токенизатора (на этапе линейной проекции), то возникает требование к фиксированному размеру изображений.
        
    \item Отсутствие оптимизации при вычислениях на графических ускорителях.
    
        Вычисление сингулярного выражения тяжело параллелизовать, из-за чего падает общая скорость обучения и работы модели. 
\end{enumerate}

Поскольку токенизатор на основе сингулярного разложения работоспособен и позволяет значительно сократить длину входной последовательности при обработке изображения, необходимо решить существующие проблемы для его эффективного обучения и использования.

\subsection{Модифицированный токенизатор на основе сингулярного разложения}

\subsubsection{Построение модифицированного токенизатора на основе сингулярного разложения без функции оценки}

Для решения проблем токенизатора на основе сингулярного разложения пришлось отказаться от использования сингулярного разложения. Алгоритм разложения был заменен на нейронную сеть, архитектура которой вдохновлена сингулярным разложением.

В алгоритме токенизации на основе сингулярного разложения, описанном в предыдущем разделе, токенизация происходит благодаря разбиению матриц $U'$ и $V'$ на наборы векторов $u$ и $v$. Для того, чтобы получить наборы векторов $u$ и $v$ с помощью нейронных сетей, воспользуемся алгоритмом пиксельной расстановки, аналогичным использованному в методе токенизации на основе быстрого преобразования Фурье. 

Для получения каждого из этих наборов построим нейронную сеть, принимающую на вход тензор размерности 

$$
(3, M, M)
$$

Данная нейронная сеть аналогична нейронной сети, предложенной в методе токенизации с использованием быстрого преобразования Фурье. Она также состоит из четырех блоков, каждый блок состоит из свёрточного слоя с размером ядра свёртки равным 3, размером шага равным 1, размером отступа равным 1 и с использованием нейрона смещения. Следом за свёрточным слоем используется слой нормализации и функция активации, после чего применяется алгоритм пиксельной расстановки. 

Таким образом, исходный тензор преобразуется в тензор размерности

$$
\Big(3 \cdot 4^4, \dfrac{M}{16}, \dfrac{M}{16}\Big)
$$

Данный тензор обрабатывается слоем проекции - свёрточным слоем с ядром свёртки размером 1, шагом свёртки размером 1, отступом размером 0 и без нейрона смещения. После этого, данный тензор выпрямляется по двум последним осям (``по ширине`` и ``по высоте``) и транспонируется. В результате получается тензор, описывающий последовательность векторов и имеющий размерность

$$
\Big(\dfrac{M^2}{16^2}, s_E\Big)
$$

Таким образом получаются наборы векторов $u$ и $v$. Аналогично методу токенизации на основе сингулярного разложения, два этих набора векторов объединяются в результате конкатенации соответствующих токенов. 

В результате получается тензор размерности

$$
\Big(\dfrac{M^2}{16^2}, 2 \cdot s_E\Big)
$$

Данный тензор с помощью линейного полносвязного слоя проецируется в пространство токенов трансформера. Итоговый тензор, описывающий последовательность токенов на вход трансформера, имеет размерность

$$
\Big(\dfrac{M^2}{16^2}, s_E\Big)
$$

Таким образом данная версия метода токенизации на основе сингулярного разложения позволяет решить проблему требования фиксированного размера изображения, поскольку динамическая переменная присутствует только в длине последовательности. Единственное требование к размеру изображения - кратность 16. Также, данная версия позволяет решить проблему отсутствия оптимизации вычисления на видеокарте, поскольку она полностью реализована с помощью слоёв нейронных сетей, оптимизированных для вычисления на графических ускорителях во всех популярных библиотеках глубокого обучения. 

Стоит отметить, что в отличие от исходного метода токенизации на основе сингулярного разложения, данный метод токенизации не выполняет фильтрацию токенов входной последовательности трансформера ни в каком виде. Из-за этого длина последовательности токенов, получаемой данным токенизатором при обработке изображения равна длине последовательности токенов, получаемом при использовании токенизатора Vision Transformer.

К итоговой последовательности токенов добавляется токен класса и позиционное кодирование, аналогичное позиционному кодированию в оригинальной модели Trasnformer.

Данная версия токенизатора названа mSVD. Общая схема представлена на \autoref{fig:msvd_scheme}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]
    {images/research/msvd/msvd_scheme.png}
    \caption{Схема токенизатора mSVD.}
    \label{fig:msvd_scheme}
\end{figure}



\subsubsection{Построение функции оценки}
Для фильтрации токенов входной последовательности была добавлена функция оценки токенов. Функция оценки токенов формирует оценку ``важности`` токена. Данная функция реализована с помощью многослойной нейронной сети.

Для обучения функции оценки, вычисляемая оценка умножается на соотвествующий токен. Это позволяет градиентам при обучении достигать весов функции оценки. Однако, без дополнительных изменений, функция оценки будет выдавать одно и то же значение. Для эффективного обучения функции оценки необходим вспомогательная функция потерь.

Первая такая функция потерь была построена на основе индекса Джини \cite{gini}. Предполагая, что оценка токена - величина положительная, к выходу функции оценки применяется функция активации Rectified Linear Unit (ReLU). 

$$
\text{ReLU}(x) = \dfrac{x + |x|}{2}
$$

Если без обучения функция оценки дает одинаковые оценки всем токенам, то необходимо штрафовать нейроную сеть за одинаковые оценки. Для этого использована такая мера неоднородности, как индекс (коэффициент) Джини.

Коэффициент Джини для непрерывных элементов вычисляется следующим образом:

$$
G(x) = \dfrac{\sum\limits_{i=1}^n\sum\limits_{j=1}^n|x_i - x_j|}{2n^2\bar x}
$$

здесь $x_i$ - элемент последовательности, $n$ - длина последовательности, совпадает с количеством токенов, $\bar x$ - среднее значение элементов последовательности.

Поскольку $G(x) = 0$ при совпадении всех элементов последовательности $x$, то функция потерь, основанная на индексе Джини, выглядит следующим образом:

$$
L_G(x) = \beta(1 - G(x)),
$$

где $\beta$ - коэффициент вспомогательной функции потерь.

Также был рассмотрен иной метод построения функции потерь, основанный на идее регуляризации.

Выход функции оценки обрабатывается с помощью функции активации сигмоида

$$
\sigma(x) = \dfrac{1}{1 + e^{-x}}
$$

Полученные после обработки результаты назовём шлюзами $g_i = \sigma(x_i)$. Шлюзы могут принимать значения от 0 до 1. Для обучения функции оценки, каждый токен последовательности умножается на соответствующий ему шлюз. Это позволяет градиентам при обучении доходить до функции оценки. 

В случае, если значение шлюза близко к нулю, то после умножения на него, соответствующий токен становится близок к нулю и оказывает меньшее влияние на результат предсказания нейронной сети. В случае, если значения шлюза близко к единице, то соответствующий токен почти не изменяется при обучении.

Для того, чтобы функция оценок не обучилась таким образом, чтобы ``пропускать`` все токены (то есть предсказывать все значения шлюзов близкими к единице), в качестве вспомогательной функции потерь используется регуляризация шлюзов:

$$
L_g = \alpha \dfrac{1}{n}\sum_{i=1}^n g_i,
$$

где $\alpha$ - коэффициент вспомогательной функции потерь.

\subsubsection{Метод фильтрации токенов}
После получения оценок выполняется фильтрация токенов. Подобно предыдущим методам, можно выделить статический метод фильтрации и динамический.

Статический метод фильтрации заключается в отборе $k$ лучших токенов по их оценкам. В этом случае после добавления позиционного кодирования к последовательности токенов изначальной длины, по оценкам отбираются $k$ лучших токенов. Таким образом, длина новой последовательности равна $k$.

Динамический метод фильтрации заключается в вычислении суммы оценок токенов (или шлюзов) и отборе наименьшего количества токенов, сумма оценок которых не меньше доли $p$ от общей суммы оценок. В случае, если в одном минибатче получаются различные значения длины последовательности, из них выбирается максимальная.

Благодаря наличию функции оценки токенов, при обучении нейронной сети с методом mSVD-токенизации можно не использовать фильтрацию. При этом во время работы нейронной сети в режиме предсказания, можно изменять гиперпараметры применяемых методов фильтрации. Так, для одного избражения возможно применение статического метода фильтрации, а для другого - динамического без необходимости переобучения исходной нейронной сети.


\subsubsection{Результаты обучения}

Сначала было проведено обучение модели с mSVD токенизатором без функции оценки для проверки и демонстрации ее работоспособности.

При обучении модели с рассматриваемым токенизатором (mSVD) без функции оценки и фильтрации токенов, размер последовательности токенов совпадает с размером последовательности при использовании токенизации Vision Transformer с размером патча 16. 

Результаты обучения представлены в \autoref{tab:msvd-tokenization-no-scorer}:

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Длина \\ входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ \hline
  \end{tabular}
    \caption{Сравнение результатов обучения моделей с использованием mSVD-токенизатора и модели Vision Transformerr}
  \label{tab:msvd-tokenization-no-scorer}
\end{table}

При использовании данного метода токенизации получается достигнуть более высоких значений метрик, уменьшив количество неверно определенных классов на четверть.

Далее было проведено обучение модели с mSVD токенизатором cо вспомогательной функцией потерь на основе индекса Джини при разных значениях коэффициента $\beta$. Для фильтрации токенов использовался динамический метод фильтрации при доле $p=0.900$.

Результаты обучения представлены в \autoref{tab:msvd-tokenization-gini}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя \\ длина входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ 
    \makecell{mSVD (Джини, $\beta=1.0$)} & 0.82 & 0.82 & 231.4 \\
    \makecell{mSVD (Джини, $\beta=0.5$)} & 0.82 & 0.82 & 231.3 \\
    \makecell{mSVD (Джини, $\beta=0.1$)} & 0.82 & 0.82 & 231.3 \\
    \hline
  \end{tabular}
    \caption{Сравнение результатов обучения моделей с использованием mSVD-токенизатора при вспомогательной функции потерь на основе коэффициента Джини и модели Vision Transformer.}
  \label{tab:msvd-tokenization-gini}
\end{table}

Получены одинаковые результаты для разных значений параметра $\alpha$. Это означает, что вспомогательная функция потерь на основе коэффициента Джини не оказывает никакого влияния на результат обучения модели. 

Также, об этом может свидетельствовать средняя длина входной последовательности. Можно заметить, что $231.4 = p \cdot 256 + 1$. Таким образом, функция оценки дает приблизительно одинаковые значения для любых токенов последовательности. Это означает, что функция потерь на основе индекса Джини неработоспособна.

Несмотря на это, стоит заметить, что итоговая модель все равно превосходит по значениям метрик Vision Transformer, имея при этом меньшую длину входной последовательности на десятую часть.

Поскольку функция потерь на основе индекса Джини оказалась неработоспособна, было проведено обучение модели с mSVD токенизатором cо вспомогательной функцией потерь на основе регуляризации шлюзов.

Фильтрация токенов отсутствует, результаты обучения представлены в \autoref{tab:msvd-tokenization-sigmoid-gating}:

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Длина \\ входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ 
    \makecell{mSVD ($\alpha = 0.0250$)} & 0.83 & 0.83 & 257 \\ 
    \makecell{mSVD ($\alpha = 0.0125$)} & 0.85 & 0.85 & 257 \\
    \makecell{mSVD ($\alpha = 0.0050$)} & 0.85 & 0.84 & 257 \\
    \hline
  \end{tabular}
    \caption{Сравнение результатов обучения моделей с использованием mSVD-токенизатора при вспомогательной функции потерь на основе регуляризации шлюзов и модели Vision Transformer}
  \label{tab:msvd-tokenization-sigmoid-gating}
\end{table}

Лучшие результаты обучения были получены при значении $\alpha = 0.0125$. По результатам этого эксперимента, данное значение параметра выбирается по умолчанию для всех последующих экспериментов. 

Можно заметить, что лучшие значения метрик при обучении рассматриваемого метода токенизации с использованием функции оценки не превосходят значения метрик при обучении метода токенизации без использования функции оценки. Это ожидаемый результат, поскольку функция оценки никак не добавляет дополнительной информации при обработке изображения.

Далее, было также проведено сравнение статического и динамического методов фильтрации токенов.

Результаты обучения представлены в \autoref{tab:msvd-tokenization-static-dynamic}:

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя \\ длина входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{mSVD} & 0.85 & 0.85 & 257 \\ 
    \hline
    \makecell{mSVD (k=1)} & 0.43 & 0.40 & 2 \\ 
    \makecell{mSVD (k=4)} & 0.52 & 0.48 & 5 \\
    \makecell{mSVD (k=16)} & 0.61 & 0.57 & 17 \\
    \makecell{mSVD (k=32)} & 0.66 & 0.63 & 33 \\
    \makecell{mSVD (k=64)} & 0.71 & 0.70 & 65 \\
    \makecell{mSVD (k=96)} & 0.76 & 0.75 & 97 \\
    \makecell{mSVD (k=128)} & 0.80 & 0.80 & 129 \\
    \makecell{mSVD (k=160)} & 0.83 & 0.83 & 161 \\
    \makecell{mSVD (k=192)} & 0.85 & 0.85 & 193 \\
    \makecell{mSVD (k=224)} & 0.85 & 0.85 & 225 \\
    \hline
    \makecell{mSVD (p=0.100)} & 0.62 & 0.58 & 23.1 \\
    \makecell{mSVD (p=0.200)} & 0.67 & 0.64 & 46.6 \\
    \makecell{mSVD (p=0.300)} & 0.71 & 0.69 & 70.0 \\
    \makecell{mSVD (p=0.400)} & 0.74 & 0.73 & 90.4 \\
    \makecell{mSVD (p=0.500)} & 0.77 & 0.77 & 120.2 \\
    \makecell{mSVD (p=0.600)} & 0.81 & 0.81 & 149.4 \\
    \makecell{mSVD (p=0.700)} & 0.83 & 0.83 & 166.0 \\
    \makecell{mSVD (p=0.800)} & 0.85 & 0.85 & 192.5 \\
    \makecell{mSVD (p=0.900)} & 0.85 & 0.85 & 228.9 \\
    \makecell{mSVD (p=0.950)} & 0.85 & 0.85 & 242.2 \\
    \makecell{mSVD (p=0.990)} & 0.85 & 0.85 & 253.6 \\
    \hline
  \end{tabular}
    \caption{Сравнение статического и динамического методов фильтрации токенов}
  \label{tab:msvd-tokenization-static-dynamic}
\end{table}

Видно, что с помощью методов фильтрации на основе оценок токенов возможно сократить длину последовательности на четверть и не потерять в качестве работы модели. При этом, если сократить длину последовательности в два раза, то значения метрик все равно будут выше, чем при использовании Vision Transformer.

\subsection{Сравнение предложенных алгоритмов токенизации изображений и существующих решений}
\subsubsection{Токенизация изображений на основе Вейвлет-преобразования}
В работе \cite{wavelet_autoregression}, где предложен метод токенизации изображений на основе Вейвлет-преобразования, основная цель метода - авторегрессионная генерация изображения. Однако, данный метод может быть адаптирован и для других задач, связанных с обработкой изображений. Например, для решения задачи многоклассовой классификации.

Однако, применить данный метод для обработки изображений размерности больше, чем (3, 32, 32) не вышло, поскольку длина последовательности токенов становится равной нескольким тысячам. Это приводит к серьезной нехватке памяти и значительно снижает скорость обработки данных.

\subsubsection{Результаты обучения и сравнение с предложенными методами}

Лучшие результаты по всем рассмотренным методам были сведены в единую таблицу (\autoref{tab:research-comparison}). В качестве FFT-токенизатора выбран токенизатор с размером статического фильтра 256, в качестве SVD-токенизатора выбран токенизатор с долей сохраненной информации равной 0.90, в качестве mSVD токенизатора был выбран токенизатор с динамической фильтрацией токенов с долей от суммы оценок равной 0.800.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    \makecell{Метод \\ токенизации} 
      & {Точность} 
      & {F1-метрика} 
      & \makecell{Средняя \\ длина входной \\ последовательности} \\ 
    \hline
    \makecell{Vision Transformer} & 0.79 & 0.79 & 257 \\
    \makecell{Вейвлет-токенизатор} & 0.50 & 0.43 & 1025 \\
    \makecell{FFT-токенизатор} & 0.79 & 0.79 & 257 \\
    \makecell{SVD-токенизатор} & 0.69 & 0.69 & 15.3 \\
    \makecell{mSVD} & 0.85 & 0.85 & 192.5 \\ 
    \hline
  \end{tabular}
    \caption{Сравнение построенных токенизаторов с токенизатором на основе Вейвлет-преобразования и Vision Transformer}
  \label{tab:research-comparison}
\end{table}


Из \autoref{tab:research-comparison} видно, что лучшие результаты были получены при использовании модели с токенизатором mSVD.

\subsection{Выводы по главе 3}

В результате исследования алгоритмов токенизации изображений на основе матричных разложений были построены рабочие методы токенизации на основе быстрого преобразования Фурье и сингулярного разложения. Однако, данные методы обладают серьезными недостатками, такими как ухудшение качества работы итоговой модели по сравнению с Vision Transformer и медленное вычисление матричных разложений, не оптимизированных для работы на видеокартах. 

Попытка решить эти недостатки привела к созданию метода токенизации mSVD, сохранившего преимущества Vision Transformer, такие как возможность параллельного вычисления и возможность обработки, и добившегося более высокой точности работы итоговой модели при меньшей длине входной последовательности. 

