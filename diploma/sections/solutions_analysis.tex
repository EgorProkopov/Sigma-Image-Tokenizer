\documentclass[times,specification,annotation]{itmo-student-thesis}
\usepackage{fancyhdr}

%% Опции пакета:
%% - specification - если есть, генерируется задание, иначе не генерируется
%% - annotation - если есть, генерируется аннотация, иначе не генерируется
%% - times - делает все шрифтом Times New Roman, собирается с помощью xelatex
%% - languages={...} - устанавливает перечень используемых языков. По умолчанию это {english,russian}.
%%                     Последний из языков определяет текст основного документа.

%% Делает запятую в формулах более интеллектуальной, например:
%% $1,5x$ будет читаться как полтора икса, а не один запятая пять иксов.
%% Однако если написать $1, 5x$, то все будет как прежде.
\usepackage{icomma}

%% Один из пакетов, позволяющий делать таблицы на всю ширину текста.
\usepackage{tabularx}

%% Данные пакеты необязательны к использованию в бакалаврских/магистерских
%% Они нужны для иллюстративных целей
%% Начало
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{filecontents}
%% Конец

%% Указываем файл с библиографией.
\addbibresource{bachelor-thesis.bib}

\begin{document}

\chapter{Анализ существующих решений}
Существуют различные методы токенизации изображения (то есть преобразования его в набор плотных векторов).

\section{Токенизация изображений Vision Transformer}
Процесс токенизации изображений в Vision Transformer подразумевает разбиение изображения на патчи.

Данный подход обладает своими преимуществами и недостатками.

\begin{itemize}
    \item По сравнению с методом попиксельной токенизации, предложенной в Image Tranformer, использование патчей вместо пикселей позволяет сократить длину входной последовательности в $N^2$ раз при условии разбиения на патчи размером $N \times N$. Например, для изображения $224 \times 224$ пикселей, количество элементов входной последовательности снижается с $224^2 = 50 176$ до $(224 / 16)^2 = 196$.
    \item Поскольку процесс разбиения изображения на патчи $N \times N$ с последующей проекцией в пространство некоторой внутренней размерности трансформера можно заменить одним сверточным слоем с размером ядра свертки $N \times N$ и шагом $N$, можно говорить о сохранении информации о простейших локальных структурах (например, о границах объектов и их текстурах) внутри одного патча.
    \item Поскольку архитектура ViT почти полностью повторяет архитектуру трансформера-кодировщика, токены выходной последовательности могут быть совместимы с текстовыми токенами после, например, линейной проекции или даже без нее. Данное свойство очень важно, поскольку используется в визуальных языковых моделях (VLM)\cite{llava} и в таких моделях, как CLIP\cite{clip} и позволяет связать текстовую модальность и модальность изображений при помощи общей архитектуры трансформера.
\end{itemize}

Однако, несмотря на ряд преимуществ, этот метод токенизации несовершенен. Некоторые из недостатков могут быть критическими при разработке современных моделей. Например, при разработке визуальных языковых моделей. К подобным недостаткам относятся:

\begin{itemize}
    \item Несмотря на сокращение длины входной последовательности в $N^2$ раз по сравнению с попиксельной токенизацией, количество патчей, а соответственно токенов, все еще линейно зависит от количества пикселей изображения. Это значит, что при линейном увеличении размера изображения, количество требуемых ресурсов будет расти квадратично. Это может быть критичным при обработке изображений большой размерности или нескольких изображений одновременно.

    \item Поскольку сетка патчей фиксирована, наиболее вероятно, что она будет разрезать объекты на своих границах. Из-за этого происходит потеря локальной целостности различных объектов. Например, лицо человека, попавшее на стык нескольких патчей, будет обработано фрагментарно. Данная проблема негативно влияет на понимание моделью локального контекста.
    
    \item Из-за фиксированного размера патчей, модель плохо адаптируется к изображениям разной размерности.  

    \item Из-за метода токенизации и фиксированной сетки разбиения, однотонные и семантически богатые патчи требуют одинакого количества вычислений на обработку. Это приводит к нерациональному использованию ресурсов.
\end{itemize}

\section{Токенизация изображений на уровне субъектов}

В статье \cite{subobject_tokenization} предложен метод токенизации изображения на основе субобъектов (семантически значимых сегментов изображения). Вместо разбиения изображения на фиксированные патчи, авторы используют модель сегментации DirectSAM для выделения структурно-осмысленных частей объектов. С помощью модели SeqAE эти сегменты преобразуются в плотные векторы.

Авторы заявляют о ускорении обучения при использовании данного метода токенизации, также, в отличие от ViT, длина последовательности зависит не от размера изображения,  а от количества объектов на нем. 

Однако это преимущество нивелируется необходимостью использовать две дополнительные модели для подготовки токенов, что значительно повышает требуемые ресурсы для работы. По этой причине, этот подход не будет рассмотрен далее, поскольку из-за своего главного недостатка делает невозможным решение задачи уменьшения требуемых для работы модели-трансформера ресурсов.

\section{Токенизация изображений на основе Вейвлет-разложения}
% Что такое Вейвлет-разложение
Вейвлет-преобразование --- инструмент для анализа изображений и сигналов. Данное преобразование выполняет разложение изображения на низкочастотную и высокочастотные составляющие. При этом, низкочастотная составляющая сохраняет большую часть информации изображения. При каждом таком преобразовании требуемый для хранения изображения объем памяти уменьшается.

% Wavelet-Based Image Tokenizer for Vision Transformers
В статье \cite{wavelet_tokenization} предложен алгоритм токенизации изображений на основе Вейвлет-разложения:

\begin{itemize}
    \item Выполняется преобразование RBG в YCbCr.
    \item Над полученным изображением в YCbCr формате выполняется Вейвлет-преобразование. Изображение разбивается на уровни детализации (LL, LH, HL и HH). Каждый уровень соответствует разным частотным компонентам.
    \item Малозначимые высокочастотные элементы обнуляются. Это позволяет сократить объем данных без существенной потери информации.
    \item Оставшиеся составляющие объединяются в тензор $W$, в котором каждый вектор соответствует локальной области пикселей.
    \item Векторы тензора $W$ из пиксельного пространства с помощью линейной проекции проецируются в пространство меньшей размерности 
    $$
    E = W Q,
    $$
    где $Q$ - матрица проекции, а $E$ --- проекция $W$ в ``семантическое`` пространство.
\end{itemize}

К преимуществам данного подхода можно отнести:

\begin{itemize}
    \item Возможность настройки детализации изображения перед его обработкой. Это позволяет значительно уменьшить длину входной последовательности и работать даже с изображениями в сверхвысоком ($N > 2048$) качестве.
    \item Устойчивость к адверсариальным атакам. Поскольку малозначимые высокочастотные составляющие обнуляются, значительно снижается влияние шумов.
    \item За счет неоднородности в высокочастотных составляющих модель фокусируется на информативных областях, пропуская малоинформативные.
\end{itemize}

Однако, у данного подхода также есть много проблем:

\begin{itemize}
    \item Зависимость производительности от гиперпараметров (таких как уровень детализации и порог округления высокочастотных признаков). Неверный выбор гиперпараметров может привести к потере слишком важных деталей или недостаточному сжатию. Таким образом для настройки гиперпараметров требуется трудоемкая работа.
    \item Вейвлет-ядра фиксированы и не способны подстраиваться под данные, что уменьшает адаптивность модели.
    \item Многократное вейвлет-преобразование требует дополнительных ресурсов.
\end{itemize}

% Wavelets Are All You Need for Autoregressive Image Generation
Несмотря на имеющиеся проблемы, методы токенизации на основе Вейвлет-преобразования получают все большее распространение. В работе \cite{wavelet_autoregression} даже предложен способ авторегрессионной генерации моделью-трансформером на основе вейвлет-разложения. 

\s\chapterconclusion
Несмотря на появление новых методов, область токенизации изображений все еще требует тчательного изучения, поскольку предлагаемые методы все еще не способны побороть алгоритм токенизации, основанный на разбиении изображений на патчи. Метод токенизации на основе Вейвлет-разложения хоть и может быть адаптирован для других задач, однако изначально предназначен только для генерации изображений, а метод токенизации изображений на основе субъектов применим в очень редких случаях, поскольку требует для своей работы дополнительную тяжеловесную модель, что значительно повышает требуемые для работы ресурсы. 

\end{document}